{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyun/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# sparse 행렬을 만들어야 하기 때문에 다음과 같이 import\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from box import Box\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "- whole data -> filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "- 모델에 넣기 위한 dataset 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/gusye1234/LightGCN-PyTorch/blob/master/code/dataloader.py\n",
    "# https://github.com/SeongBeomLEE/RecsysTutorial/blob/main/LightGCN/LightGCN.ipynb\n",
    "# https://radish-greens.tistory.com/1\n",
    "## 참고하여 재정의\n",
    "\n",
    "class Preprocess :\n",
    "    def __init__(self, data_path, config) : \n",
    "        self.data = pd.read_csv(data_path, usecols=['user_id', 'product_id','rating','unixReviewTime'], header=0)\n",
    "        # self.data = self.data[['user_id', 'product_id','interaction','timestamp']]\n",
    "        self.config = config\n",
    "        # bpr을 이용하기 때문에 encoder, decoder의 구조가 필요\n",
    "        ## 유저, 아이템 행렬에 대한 각각의 encoder, decoder가 필요\n",
    "        self.user_encoder, self.user_decoder, self.num_users = self._encode_user()\n",
    "        self.item_encoder, self.item_decoder, self.num_items = self._encode_item()\n",
    "\n",
    "        # 유저와 아이템의 관계에 대한 인접행렬 생산\n",
    "        #  build a graph in torch.sparse.IntTensor.\n",
    "        # Details in NGCF's matrix form\n",
    "        # A = \n",
    "        #     |I,   R|\n",
    "        #     |R^T, I|\n",
    "        # \"\"\"\n",
    "        self.user_item_matrix = self._generate_user_item_matrix()\n",
    "        self.adjacency_matrix = self._generate_adjacency_matrix() \n",
    "\n",
    "\n",
    "        self.exist_users = list(self.user_encoder.values())  # 혹은 다른 방식으로 존재하는 사용자 ID 목록 생성\n",
    "        self.exist_items = list(self.item_encoder.values())  # 존재하는 아이템 ID 목록\n",
    "        self.user_train = self._generate_user_train()  # 사용자별 긍정 아이템 목록을 생성하는 메서드 필요\n",
    "\n",
    "    def _encode_user(self) :\n",
    "        unique_users = self.data['user_id'].unique()\n",
    "        user_encoder = {user_id:idx for idx, user_id in enumerate(unique_users)}\n",
    "        user_decoder = {idx:user_id for user_id, idx in user_encoder.items()}\n",
    "        return user_encoder,user_decoder,len(unique_users)\n",
    "\n",
    "    def _encode_item(self) : \n",
    "        unique_items = self.data['product_id'].unique()\n",
    "        item_encoder = {item_id:idx for idx, item_id in enumerate(unique_items)}\n",
    "        item_decoder = {idx:item_id for item_id, idx in item_encoder.items()}\n",
    "        \n",
    "        return item_encoder,item_decoder,len(unique_items)\n",
    "\n",
    "    def _generate_user_item_matrix(self) :\n",
    "        # matrix에 들어갈 내용을 정합니다.\n",
    "        # rows, cols, value로 구성됨 \n",
    "        rows = self.data['user_id'].map(self.user_encoder)\n",
    "        cols = self.data['product_id'].map(self.item_encoder)\n",
    "        values = np.ones(len(self.data))\n",
    "        user_item_matrix = sp.csr_matrix((values, (rows,cols)), shape=(self.num_users, self.num_items))\n",
    "        return user_item_matrix\n",
    "\n",
    "    def _generate_adjacency_matrix(self) : \n",
    "        # user에 대한 그래프 + 아이템에 대한 그래프에 대한 인접그래프 생성\n",
    "        user_item_matrix = self.user_item_matrix\n",
    "        item_user_matrix = self.user_item_matrix.transpose()\n",
    "\n",
    "        zero_user_to_user = sp.csr_matrix((self.num_users, self.num_users))\n",
    "        zero_item_to_item = sp.csr_matrix((self.num_items, self.num_items))\n",
    "\n",
    "        # 상단 블록 (사용자-사용자 연결 및 사용자-아이템 연결)\n",
    "        upper_block = sp.hstack([zero_user_to_user, user_item_matrix], format='csr')\n",
    "        # 하단 블록 (아이템-사용자 연결 및 아이템-아이템 연결)\n",
    "        lower_block = sp.hstack([item_user_matrix, zero_item_to_item], format='csr')\n",
    "\n",
    "        adjacency_matrix = sp.vstack([upper_block, lower_block], format='csr')\n",
    "\n",
    "        return adjacency_matrix\n",
    "\n",
    "    def _generate_user_train(self) :\n",
    "        user_train = {}\n",
    "        for _, row in self.data.iterrows() :\n",
    "            user_id = self.user_encoder[row.user_id]\n",
    "            item_id = self.item_encoder[row.product_id]\n",
    "            if user_id not in user_train :\n",
    "                user_train[user_id] = []\n",
    "            user_train[user_id].append(item_id)\n",
    "        return user_train\n",
    "\n",
    "    def sampling(self):\n",
    "        users = random.sample(self.exist_users, self.config['n_batch'])\n",
    "\n",
    "        def sample_pos_items_for_u(u, num):\n",
    "            pos_items = self.user_train[u]\n",
    "            pos_batch = random.sample(pos_items, num)\n",
    "            return pos_batch\n",
    "\n",
    "        def sample_neg_items_for_u(u, num):\n",
    "            neg_items = list(set(self.exist_items) - set(self.user_train[u]))\n",
    "            neg_batch = random.sample(neg_items, num)\n",
    "            return neg_batch\n",
    "\n",
    "        pos_items, neg_items = [], []\n",
    "        for user in users:\n",
    "            pos_items += sample_pos_items_for_u(user, 1)\n",
    "            neg_items += sample_neg_items_for_u(user, 1)\n",
    "\n",
    "        return users, pos_items, neg_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightgcn의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원저자와의 차이\n",
    "\n",
    "1. 모델 초기화 차이\n",
    "- xavier -> normal\n",
    "2. dropout 처리\n",
    "- 원저자 : dropout 생략\n",
    "- 내 구조 : 추가\n",
    "3. forward\n",
    "- 원저자 : graph convolution 직접 계산, 모든 layer의 임베딩을 평균 -> 최종 임베딩\n",
    "- 내 구조 : 간략한 계산\n",
    "4. loss function\n",
    "- 원저자 : BPR class 직접 사용\n",
    "    - 파라미터 업데이트에 사용되는 optimizer 관리\n",
    "- 내 구조 : BPR 직접계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim, n_layers, reg, adj_mtx, device):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.l = adj_mtx\n",
    "        self.graph = self._convert_sp_mat_to_sp_tensor(self.l)\n",
    "\n",
    "        self.reg = reg\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim).to(device)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=emb_dim).to(device)\n",
    "\n",
    "        # Initialize embeddings\n",
    "        torch.nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "        torch.nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "        self.adj_mtx = self._convert_sp_mat_to_sp_tensor(adj_mtx).to(device)\n",
    "\n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    def forward(self, user, pos_item, neg_item):\n",
    "        \"\"\"\n",
    "        Computes the forward pass\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "        user = user\n",
    "        pos_item = positive item (user interacted with item)\n",
    "        neg_item = negative item (user did not interact with item)\n",
    "        \"\"\"\n",
    "\n",
    "        all_embeddings = self.compute_embeddings()\n",
    "\n",
    "        u_embeddings = all_embeddings[:self.n_users]\n",
    "        i_embeddings = all_embeddings[self.n_users:]\n",
    "\n",
    "        users_emb = u_embeddings[user]\n",
    "        pos_emb = i_embeddings[pos_item]\n",
    "        neg_emb = i_embeddings[neg_item]\n",
    "\n",
    "        pos_scores = torch.sum(users_emb * pos_emb, dim=-1)\n",
    "        neg_scores = torch.sum(users_emb * neg_emb, dim=-1)\n",
    "\n",
    "        loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "        # Regularization term\n",
    "        if self.reg > 0:\n",
    "            reg_term = (1/2)*(users_emb.norm(2).pow(2) + \n",
    "                              pos_emb.norm(2).pow(2) + \n",
    "                              neg_emb.norm(2).pow(2))/float(len(user))\n",
    "            loss += self.reg * reg_term\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_embeddings(self):\n",
    "        users_emb = self.user_embedding.weight\n",
    "        items_emb = self.item_embedding.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb])\n",
    "\n",
    "        embs = [all_emb]\n",
    "        for _ in range(self.n_layers):\n",
    "            all_emb = torch.sparse.mm(self.adj_mtx, all_emb)\n",
    "            embs.append(all_emb)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        light_out = torch.mean(embs, dim=1)\n",
    "        return light_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LightGCN(nn.Module):\n",
    "#     # dropout 제거\n",
    "#     # def __init__(self, n_users, n_items, emb_dim, n_layers, reg, node_dropout, adj_mtx):\n",
    "#     def __init__(self, n_users, n_items, emb_dim, n_layers, reg, adj_mtx, device):\n",
    "#         super().__init__()\n",
    "#         # initialize Class attributes\n",
    "#         self.n_users = n_users\n",
    "#         self.n_items = n_items\n",
    "#         self.emb_dim = emb_dim\n",
    "        \n",
    "#         self.l = adj_mtx\n",
    "#         self.graph = self._convert_sp_mat_to_sp_tensor(self.l)\n",
    "\n",
    "#         self.reg = reg\n",
    "#         self.n_layers = n_layers\n",
    "#         self.device = device\n",
    "#         # --------------------------------\n",
    "#         # 제거\n",
    "#         # self.node_dropout = node_dropout\n",
    "\n",
    "#         # Initialize weights\n",
    "#         # self.weight_dict = self._init_weights()\n",
    "#         # print(\"Weights initialized.\")\n",
    "\n",
    "#     # # initialize weights\n",
    "#     # def _init_weights(self):\n",
    "#     #     print(\"Initializing weights...\")\n",
    "#     #     weight_dict = nn.ParameterDict()\n",
    "\n",
    "#     #     # initializer = torch.nn.init.xavier_uniform_\n",
    "#     #     initializer = torch.nn.init.normal_\n",
    "        \n",
    "#     #     weight_dict['user_embedding'] = nn.Parameter(initializer(torch.empty(self.n_users, self.emb_dim).to(device)))\n",
    "#     #     weight_dict['item_embedding'] = nn.Parameter(initializer(torch.empty(self.n_items, self.emb_dim).to(device)))\n",
    "\n",
    "#     #     return weight_dict\n",
    "#     # --------------------------------\n",
    "#         self.user_embedding = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim).to(device)\n",
    "#         self.item_embedding = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=emb_dim).to(device)\n",
    "        \n",
    "#         # Initialize embeddings\n",
    "#         torch.nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "#         torch.nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "#         self.adj_mtx = self._convert_sp_mat_to_sp_tensor(adj_mtx).to(device)\n",
    "\n",
    "\n",
    "#     # convert sparse matrix into sparse PyTorch tensor\n",
    "#     def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "#         \"\"\"\n",
    "#         Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "#         Arguments:\n",
    "#         ----------\n",
    "#         X = Adjacency matrix, scipy sparse matrix\n",
    "#         \"\"\"\n",
    "#         coo = X.tocoo().astype(np.float32)\n",
    "#         i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "#         v = torch.FloatTensor(coo.data)\n",
    "#         res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "#         return res\n",
    "#     # 드랍아웃을 사용하지 않는 경우 주석처리\n",
    "#     # apply node_dropout\n",
    "#     # def _droupout_sparse(self, X):\n",
    "#     #     \"\"\"\n",
    "#     #     Drop individual locations in X\n",
    "        \n",
    "#     #     Arguments:\n",
    "#     #     ---------\n",
    "#     #     X = adjacency matrix (PyTorch sparse tensor)\n",
    "#     #     dropout = fraction of nodes to drop\n",
    "#     #     noise_shape = number of non non-zero entries of X\n",
    "#     #     \"\"\"\n",
    "#     #     node_dropout_mask = ((self.node_dropout) + torch.rand(X._nnz())).floor().bool().to(device)\n",
    "#     #     i = X.coalesce().indices()\n",
    "#     #     v = X.coalesce()._values()\n",
    "#     #     i[:,node_dropout_mask] = 0\n",
    "#     #     v[node_dropout_mask] = 0\n",
    "#     #     X_dropout = torch.sparse.FloatTensor(i, v, X.shape).to(X.device)\n",
    "\n",
    "#     #     return  X_dropout.mul(1/(1-self.node_dropout))\n",
    "\n",
    "#     def forward(self, user, pos_item, neg_item):\n",
    "#         \"\"\"\n",
    "#         Computes the forward pass\n",
    "        \n",
    "#         Arguments:\n",
    "#         ---------\n",
    "#         user = user\n",
    "#         pos_item = positive item (user interacted with item)\n",
    "#         neg_item = negative item (user did not interact with item)\n",
    "#         \"\"\"\n",
    "        \n",
    "#         all_embeddings = self.compute_embeddings()\n",
    "        \n",
    "#         u_embeddings = all_embeddings[:self.n_users]\n",
    "#         i_embeddings = all_embeddings[self.n_users:]\n",
    "\n",
    "#         users_emb = u_embeddings[user]\n",
    "#         pos_emb = i_embeddings[pos_item]\n",
    "#         neg_emb = i_embeddings[neg_item]\n",
    "\n",
    "#         pos_scores = torch.sum(users_emb * pos_emb, dim=-1)\n",
    "#         neg_scores = torch.sum(users_emb * neg_emb, dim=-1)\n",
    "\n",
    "#         loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "#         # Regularization term\n",
    "#         if self.reg > 0:\n",
    "#             reg_term = (1/2)*(users_emb.norm(2).pow(2) + \n",
    "#                               pos_emb.norm(2).pow(2) + \n",
    "#                               neg_emb.norm(2).pow(2))/float(len(user))\n",
    "#             loss += self.reg * reg_term\n",
    "\n",
    "#         return loss\n",
    "\n",
    "#     def compute_embeddings(self):\n",
    "#         users_emb = self.user_embedding.weight\n",
    "#         items_emb = self.item_embedding.weight\n",
    "#         all_emb = torch.cat([users_emb, items_emb])\n",
    "\n",
    "#         embs = [all_emb]\n",
    "#         for _ in range(self.n_layers):\n",
    "#             all_emb = torch.sparse.mm(self.adj_mtx, all_emb)\n",
    "#             embs.append(all_emb)\n",
    "\n",
    "#         embs = torch.stack(embs, dim=1)\n",
    "#         light_out = torch.mean(embs, dim=1)\n",
    "#         return light_out\n",
    "#         # # apply drop-out mask\n",
    "#         # graph = self._droupout_sparse(self.graph) if self.node_dropout > 0 else self.graph\n",
    "#         # ego_embeddings = torch.cat([self.weight_dict['user_embedding'], self.weight_dict['item_embedding']], 0)\n",
    "#         # final_embeddings = [ego_embeddings]\n",
    "\n",
    "#         # for k in range(self.n_layers):\n",
    "#         #     ego_embeddings = torch.sparse.mm(graph, final_embeddings[k])\n",
    "#         #     final_embeddings.append(ego_embeddings)                                       \n",
    "\n",
    "#         # final_embeddings = torch.stack(final_embeddings, dim=1)\n",
    "#         # final_embeddings = torch.mean(final_embeddings, dim=1)\n",
    "        \n",
    "#         # u_final_embeddings, i_final_embeddings = final_embeddings.split([self.n_users, self.n_items], 0)\n",
    "\n",
    "#         # self.u_final_embeddings = nn.Parameter(u_final_embeddings)\n",
    "#         # self.i_final_embeddings = nn.Parameter(i_final_embeddings)\n",
    "        \n",
    "#         # # loss 계산\n",
    "#         # u_emb = u_final_embeddings[u] # user embeddings\n",
    "#         # p_emb = i_final_embeddings[i] # positive item embeddings\n",
    "#         # n_emb = i_final_embeddings[j] # negative item embeddings\n",
    "        \n",
    "#         # y_ui = torch.sum(torch.mul(u_emb, p_emb), dim = 1)                        \n",
    "#         # y_uj = torch.sum(torch.mul(u_emb, n_emb), dim = 1)\n",
    "        \n",
    "#         # log_prob = torch.mean(torch.log(torch.sigmoid(y_ui - y_uj))) \n",
    "#         # bpr_loss = -log_prob        \n",
    "#         # if self.reg > 0.:\n",
    "#         #     l2norm = (torch.sum(u_emb**2)/2. + torch.sum(p_emb**2)/2. + torch.sum(n_emb**2)/2.) / u_emb.shape[0]\n",
    "#         #     l2reg = self.reg * l2norm\n",
    "#         #     bpr_loss += l2reg\n",
    "\n",
    "#         # return bpr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, make_graph_data_set, optimizer, n_batch, device):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "    for _ in tqdm(range(n_batch), desc=\"Training...\"):\n",
    "        user, pos, neg = make_graph_data_set.sampling()\n",
    "        user = torch.LongTensor(user).to(device)\n",
    "        pos = torch.LongTensor(pos).to(device)\n",
    "        neg = torch.LongTensor(neg).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(user, pos, neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_val += loss.item()\n",
    "    return loss_val / n_batch\n",
    "\n",
    "def split_matrix(X, n_splits=10):\n",
    "    splits = []\n",
    "    chunk_size = X.shape[0] // n_splits\n",
    "    for i in range(n_splits):\n",
    "        start = i * chunk_size\n",
    "        end = X.shape[0] if i == n_splits - 1 else (i + 1) * chunk_size\n",
    "        splits.append(X[start:end])\n",
    "    return splits\n",
    "\n",
    "\n",
    "# def compute_ndcg_k(pred_items, test_items, k):\n",
    "#     # DCG 계산\n",
    "#     # print(f\"test_items : {test_items.shape}\")\n",
    "#     topk_preds = pred_items[:, :k]\n",
    "#     # print(f\"topk_preds shape : {topk_preds.shape}\")\n",
    "#     tp = (test_items * topk_preds).sum(dim=1)\n",
    "#     log_pos = torch.log2(torch.arange(2, k + 2, device=pred_items.device).float())\n",
    "#     dcg = (tp / log_pos).sum(dim=1)\n",
    "#     # IDCG 계산\n",
    "#     ideal_tp = torch.sort(test_items, dim=1, descending=True)[0][:, :k]\n",
    "#     idcg = (ideal_tp / log_pos).sum(dim=1)\n",
    "#     idcg[idcg == 0] = 1  # 0으로 나누는 것을 방지\n",
    "#     ndcg = dcg / idcg\n",
    "#     return ndcg.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred_items, test_items, k, i_embeddings):\n",
    "    \"\"\"\n",
    "    예측된 아이템 점수와 실제 테스트 아이템 간의 Recall, Precision, F1 점수를 계산합니다.\n",
    "\n",
    "    :param pred_items: 예측된 아이템 점수 (사용자 수 x 아이템 수)\n",
    "    :param test_items: 실제 테스트 아이템 (사용자 수 x 아이템 수), 1과 0으로 이루어진 행렬\n",
    "    :param k: 상위 k 개의 아이템을 고려\n",
    "    :return: recall@k, precision@k, F1@k, ndcg\n",
    "    : 추가 return : diversity 계산 결과\n",
    "    \"\"\"\n",
    "    _, topk_indices = torch.topk(pred_items, k=k, dim=1)\n",
    "    topk_preds = torch.zeros_like(pred_items).float()\n",
    "    topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "    # Recall@k: (TP) / (TP + FN)\n",
    "    tp = (test_items * topk_preds).sum(1)\n",
    "    recall = (tp / test_items.sum(1)).mean()\n",
    "\n",
    "    # Precision@k: (TP) / (TP + FP)\n",
    "    precision = (tp / k).mean()\n",
    "\n",
    "    # F1 Score: 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)  # NaN 값 처리\n",
    "    \n",
    "    # https://walwalgabu.tistory.com/entry/4-NDCG-Normalized-Discounted-Cumulative-Gain%ED%8F%89%EA%B0%80%EC%A7%80%ED%91%9C\n",
    "    # NDCG\n",
    "    \n",
    "    # topk에 대한 실제 값 가져오기\n",
    "    relevant_scores = torch.gather(test_items, 1, topk_indices)\n",
    "    \n",
    "    log_pos = torch.log2(torch.arange(2, k+2, device=pred_items.device).float())\n",
    "    dcg = (relevant_scores / log_pos).sum(dim=1)\n",
    "    \n",
    "    # ideal DCG 계산\n",
    "    _, sorted_indices = torch.sort(test_items, dim=1, descending=True)\n",
    "    ideal_scores = torch.gather(test_items, 1, sorted_indices)[:, :k]\n",
    "    idcg = (ideal_scores / log_pos).sum(dim=1)\n",
    "    \n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0  # NaN 처리\n",
    "    \n",
    "    # diversity 계산\n",
    "    diversity = calculate_diversity(i_embeddings, topk_indices)\n",
    "    \n",
    "    # f1와 diversity의 조화평균으로 trade off 계산\n",
    "    # https://aclanthology.org/2022.coling-1.332.pdf\n",
    "    \n",
    "    trade_off = 2* (diversity * f1) / (diversity + f1 + 1e-8)\n",
    "\n",
    "    \n",
    "    # log_pos = torch.log2(torch.arange(2, k+2, device=pred_items.device).float())\n",
    "    # # log_pos, tp의 크기 일치를 위해 unsqueeze\n",
    "    # log_pos_expanded = log_pos.unsqueeze(0).expand(pred_items.size(0), -1)\n",
    "\n",
    "    # dcg = (tp.unsqueeze(1) / log_pos_expanded).sum(dim=1)\n",
    "    # ideal = torch.sort(test_items, dim=1, descending=True)[0][:, :k]\n",
    "    # idcg = (ideal / log_pos).sum(dim=1)\n",
    "    # idcg[idcg==0] = 1\n",
    "    # ndcg = dcg / idcg\n",
    "\n",
    "    # https://velog.io/@rockgoat2/Recommendation-System-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EC%97%AC%EB%9F%AC-Measure-Beyond-Accuracy\n",
    "    ## intra list diversity를 확인하여 비슷한 속성으로 아이템이 구성되는 것을 지양하기 위한 확인 metric으로 활용\n",
    "    \n",
    "    return recall.item(), precision.item(), f1.mean().item(), torch.mean(ndcg).item(), diversity, trade_off\n",
    "\n",
    "def calculate_diversity(item_embeddings, topk_indices) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        item_embeddings : 아이템의 임베딩 tensor (item, embedding)\n",
    "        topk_indices : 사용자 별 추천된 k개 아이템의 idx tensor (user,k)\n",
    "        similarity : cosine similarity\n",
    "        return : divergence 계수\n",
    "    \"\"\"\n",
    "    n_users, k = topk_indices.size()\n",
    "    similarity = 0\n",
    "\n",
    "    for i in range(k) :\n",
    "        for j in range(i+1, k) :\n",
    "            item_i_emb = item_embeddings[topk_indices[:, i]]\n",
    "            item_j_emb = item_embeddings[topk_indices[:, j]]\n",
    "            sim = F.cosine_similarity(item_i_emb, item_j_emb, dim=1)\n",
    "            similarity += sim\n",
    "\n",
    "    avg_sim = similarity / (k * (k-1) / 2)\n",
    "    diversity = 1 - avg_sim\n",
    "\n",
    "    return diversity.mean()\n",
    "\n",
    "\n",
    "def evaluate(model, Rtr, Rte, k, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = model.compute_embeddings()\n",
    "        u_embeddings = all_embeddings[:model.n_users]\n",
    "        i_embeddings = all_embeddings[model.n_users:]\n",
    "\n",
    "        scores = torch.matmul(u_embeddings, i_embeddings.T)\n",
    "\n",
    "        # 실제 테스트 데이터와 비교할 수 있도록 변환\n",
    "        test_items = torch.FloatTensor(Rte.toarray()).to(device)\n",
    "\n",
    "        recall, precision, f1, ndcg, diversity, trade_off = compute_metrics(scores, test_items, k, i_embeddings)\n",
    "    return recall, precision, f1, ndcg, diversity, trade_off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def user_cosine(u_embeddings) :\n",
    "    user_embeddings_to_numpy = u_embeddings.cpu().detach().numpy()\n",
    "    # 유저 임베딩 L2 normalization\n",
    "    faiss.normalize_L2(user_embeddings_to_numpy)\n",
    "    \n",
    "    d = user_embeddings_to_numpy.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    \n",
    "    index.add(user_embeddings_to_numpy)\n",
    "    \n",
    "    return index\n",
    "\n",
    "def similar(index, u_embeddings, user_id, k=10) : \n",
    "    query_embedding = np.expand_dims(u_embeddings[user_id].cpu().detach().numpy(), axis=0)\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    # 유사한 유저 검색\n",
    "    D, I = index.search(query_embedding, k)\n",
    "    return D, I\n",
    "\n",
    "def random_cosine(index, u_embeddings, ratio=0.1) : \n",
    "    n_users = u_embeddings.shape[0]\n",
    "    sample_size = int(n_users*ratio)\n",
    "    \n",
    "    sampled_indeces = np.random.choice(n_users, size=sample_size, replace=False)\n",
    "    \n",
    "    sampled_cosine = []\n",
    "    \n",
    "    for user_id in sampled_indeces :\n",
    "        emb = np.expand_dims(u_embeddings[user_id].cpu().detach().numpy(), axis=0)\n",
    "        faiss.normalize_L2(emb)\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        D, _ = index.search(emb, k=2)  # 자기 자신을 제외한 가장 가까운 유저와의 유사도\n",
    "        sampled_cosine.append(D[0][1:])  # 자기 자신을 제외한 결과\n",
    "    \n",
    "    # 평균 코사인 유사도를 계산\n",
    "    average_cosine_similarity = np.mean(sampled_cosine)\n",
    "    return average_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "\n",
    "# def compute_metrics(pred_items, test_items, k, i_embeddings, u_embeddings):\n",
    "#     \"\"\"\n",
    "#     예측된 아이템 점수와 실제 테스트 아이템 간의 Recall, Precision, F1 점수를 계산합니다.\n",
    "\n",
    "#     :param pred_items: 예측된 아이템 점수 (사용자 수 x 아이템 수)\n",
    "#     :param test_items: 실제 테스트 아이템 (사용자 수 x 아이템 수), 1과 0으로 이루어진 행렬\n",
    "#     :param k: 상위 k 개의 아이템을 고려\n",
    "#     :return: recall@k, precision@k, F1@k, ndcg\n",
    "#     : 추가 return : diversity 계산 결과\n",
    "#     \"\"\"\n",
    "#     _, topk_indices = torch.topk(pred_items, k=k, dim=1)\n",
    "#     topk_preds = torch.zeros_like(pred_items).float()\n",
    "#     topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "#     # Recall@k: (TP) / (TP + FN)\n",
    "#     tp = (test_items * topk_preds).sum(1)\n",
    "#     recall = (tp / test_items.sum(1)).mean()\n",
    "\n",
    "#     # Precision@k: (TP) / (TP + FP)\n",
    "#     precision = (tp / k).mean()\n",
    "\n",
    "#     # F1 Score: 2 * (precision * recall) / (precision + recall)\n",
    "#     f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "#     f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)  # NaN 값 처리\n",
    "    \n",
    "#     # https://walwalgabu.tistory.com/entry/4-NDCG-Normalized-Discounted-Cumulative-Gain%ED%8F%89%EA%B0%80%EC%A7%80%ED%91%9C\n",
    "#     # NDCG\n",
    "    \n",
    "#     # topk에 대한 실제 값 가져오기\n",
    "#     relevant_scores = torch.gather(test_items, 1, topk_indices)\n",
    "    \n",
    "#     log_pos = torch.log2(torch.arange(2, k+2, device=pred_items.device).float())\n",
    "#     dcg = (relevant_scores / log_pos).sum(dim=1)\n",
    "    \n",
    "#     # ideal DCG 계산\n",
    "#     _, sorted_indices = torch.sort(test_items, dim=1, descending=True)\n",
    "#     ideal_scores = torch.gather(test_items, 1, sorted_indices)[:, :k]\n",
    "#     idcg = (ideal_scores / log_pos).sum(dim=1)\n",
    "    \n",
    "#     ndcg = dcg / idcg\n",
    "#     ndcg[torch.isnan(ndcg)] = 0  # NaN 처리\n",
    "    \n",
    "#     # diversity 계산\n",
    "#     cosine, ILD = calculate_diversity(i_embeddings, topk_indices, u_embeddings)\n",
    "    \n",
    "#     # f1와 diversity의 조화평균으로 trade off 계산\n",
    "#     # https://aclanthology.org/2022.coling-1.332.pdf\n",
    "    \n",
    "#     trade_off = 2* (ILD * f1) / (ILD + f1 + 1e-8)\n",
    "\n",
    "    \n",
    "#     # log_pos = torch.log2(torch.arange(2, k+2, device=pred_items.device).float())\n",
    "#     # # log_pos, tp의 크기 일치를 위해 unsqueeze\n",
    "#     # log_pos_expanded = log_pos.unsqueeze(0).expand(pred_items.size(0), -1)\n",
    "\n",
    "#     # dcg = (tp.unsqueeze(1) / log_pos_expanded).sum(dim=1)\n",
    "#     # ideal = torch.sort(test_items, dim=1, descending=True)[0][:, :k]\n",
    "#     # idcg = (ideal / log_pos).sum(dim=1)\n",
    "#     # idcg[idcg==0] = 1\n",
    "#     # ndcg = dcg / idcg\n",
    "\n",
    "#     # https://velog.io/@rockgoat2/Recommendation-System-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98-%EC%97%AC%EB%9F%AC-Measure-Beyond-Accuracy\n",
    "#     ## intra list diversity를 확인하여 비슷한 속성으로 아이템이 구성되는 것을 지양하기 위한 확인 metric으로 활용\n",
    "    \n",
    "#     return recall.item(), precision.item(), f1.mean().item(), torch.mean(ndcg).item(), cosine, ILD, trade_off\n",
    "\n",
    "# def calculate_diversity(item_embeddings, topk_indices, u_embeddings) :\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         item_embeddings : 아이템의 임베딩 tensor (item, embedding)\n",
    "#         topk_indices : 사용자 별 추천된 k개 아이템의 idx tensor (user,k)\n",
    "#         similarity : cosine similarity\n",
    "#         return : 코사인 유사도 및 ILD 반환\n",
    "#     \"\"\"\n",
    "#     n_users, k = topk_indices.size()\n",
    "#     pair_count = 0\n",
    "#     ild_sum = 0\n",
    "\n",
    "#     for i in range(k) :\n",
    "#         for j in range(i+1, k) :\n",
    "#             item_i_emb =item_embeddings[topk_indices[:, i]]\n",
    "#             item_j_emb =item_embeddings[topk_indices[:, j]]\n",
    "            \n",
    "#             distance = torch.norm(item_i_emb - item_j_emb, dim=1)\n",
    "            \n",
    "#             ild_sum += distance\n",
    "#             pair_count += 1\n",
    "#     ILD = ild_sum / pair_count if pair_count > 0 else 0\n",
    "    \n",
    "    \n",
    "#     user_similarity_sum = 0\n",
    "#     user_pair_count = 0\n",
    "#     for i in range(n_users):\n",
    "#         for j in range(i + 1, n_users):\n",
    "#             user_i_emb = u_embeddings[i].unsqueeze(0)\n",
    "#             user_j_emb = u_embeddings[j].unsqueeze(0)\n",
    "#             sim = F.cosine_similarity(user_i_emb, user_j_emb)\n",
    "#             user_similarity_sum += sim\n",
    "#             user_pair_count += 1\n",
    "\n",
    "#     user_cosine_similarity = user_similarity_sum / user_pair_count if user_pair_count > 0 else 0\n",
    "\n",
    "#     return user_cosine_similarity.mean().item(), ILD.mean().item()\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate(model, Rtr, Rte, k, device):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         all_embeddings = model.compute_embeddings()\n",
    "#         u_embeddings = all_embeddings[:model.n_users]\n",
    "#         i_embeddings = all_embeddings[model.n_users:]\n",
    "\n",
    "#         scores = torch.matmul(u_embeddings, i_embeddings.T)\n",
    "\n",
    "#         # 실제 테스트 데이터와 비교할 수 있도록 변환\n",
    "#         test_items = torch.FloatTensor(Rte.toarray()).to(device)\n",
    "        \n",
    "#         recall, precision, f1, ndcg, cosine, ILD, trade_off = compute_metrics(scores, test_items, k, i_embeddings, u_embeddings)\n",
    "#     return recall, precision, f1, ndcg, cosine, ILD, trade_off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"emb_dim\": 64,\n",
    "    \"n_layers\": 3,\n",
    "    \"reg\": 0.00001,\n",
    "    \"node_dropout\": 0.1,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 50,\n",
    "    \"n_batch\": 256,  \n",
    "    \"model_path\": \"/home/siyun/ephemeral/lightgcn/models\",\n",
    "    \"model_name\": \"rating4_lightgcn_model_filtered.pt\",\n",
    "    'device' : 'device',\n",
    "    'weight_decay' : 0.0001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/home/siyun/ephemeral/lightgcn/data/'\n",
    "# data = pd.read_csv(data_path + 'rating_filtered_4.csv', usecols=['reviewerID', 'asin','rating','unixReviewTime'], header=0)\n",
    "# data['asin'], data['reviewerID'] = data['reviewerID'], data['asin']\n",
    "# data = data.rename(columns = {'asin' : 'user_id', 'reviewerID' : 'product_id'})\n",
    "# data.to_csv('/home/siyun/ephemeral/lightgcn/data/rating_filtered_4_col_change.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "data_path = '/home/siyun/ephemeral/lightgcn/data/rating_4_and_1_col_change.csv'  \n",
    "\n",
    "preprocess = Preprocess(data_path=data_path, config=config)\n",
    "\n",
    "# 인접 행렬 및 사용자, 아이템 수 등 필요한 정보 가져오기\n",
    "adjacency_matrix = preprocess.adjacency_matrix\n",
    "num_users = preprocess.num_users\n",
    "num_items = preprocess.num_items\n",
    "\n",
    "model = LightGCN(\n",
    "    n_users=num_users,\n",
    "    n_items=num_items,\n",
    "    emb_dim=config['emb_dim'],  # 임베딩 차원\n",
    "    n_layers=config['n_layers'],  # GCN 레이어\n",
    "    reg=config['reg'],  # 정규화 \n",
    "    # node_dropout=0.1,  # 드롭아웃 \n",
    "    adj_mtx=adjacency_matrix,  # 인접 행렬\n",
    "    device = device\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random sampling과 성능을 비교하기 위해 생성\n",
    "\n",
    "가장 많이 선택된 아이템의 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_random(pred_items, test_items, k, device):\n",
    "    \"\"\"\n",
    "    예측된 아이템 점수와 실제 테스트 아이템 간의 Recall, Precision, F1 점수를 계산\n",
    "\n",
    "    :param pred_items: 예측된 아이템 점수 (사용자 수 x 아이템 수)\n",
    "    :param test_items: 실제 테스트 아이템 (사용자 수 x 아이템 수), 1과 0으로 이루어진 행렬\n",
    "    :param k: 상위 k 개의 아이템을 고려\n",
    "    :return: recall@k, precision@k, F1@k\n",
    "    \"\"\"\n",
    "    _, topk_indices = torch.topk(pred_items, k=k, dim=1)\n",
    "    topk_preds = torch.zeros_like(pred_items).float()\n",
    "    topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "    # Recall@k: (TP) / (TP + FN)\n",
    "    tp = (test_items * topk_preds).sum(1)\n",
    "    recall = (tp / test_items.sum(1)).mean()\n",
    "\n",
    "    # Precision@k: (TP) / (TP + FP)\n",
    "    precision = (tp / k).mean()\n",
    "\n",
    "    # F1 Score: 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)  # NaN 값 처리\n",
    "    \n",
    "    # https://walwalgabu.tistory.com/entry/4-NDCG-Normalized-Discounted-Cumulative-Gain%ED%8F%89%EA%B0%80%EC%A7%80%ED%91%9C\n",
    "    # NDCG\n",
    "    log_pos = torch.log2(torch.arange(2, k+2, device=pred_items.device).float())\n",
    "    # log_pos, tp의 크기 일치를 위해 unsqueeze\n",
    "    log_pos_expanded = log_pos.unsqueeze(0).expand(pred_items.size(0), -1)\n",
    "\n",
    "    dcg = (tp.unsqueeze(1) / log_pos_expanded).sum(dim=1)\n",
    "    ideal = torch.sort(test_items, dim=1, descending=True)[0][:, :k]\n",
    "    idcg = (ideal / log_pos).sum(dim=1)\n",
    "    idcg[idcg==0] = 1\n",
    "    ndcg = (dcg / idcg).mean()\n",
    "\n",
    "    return recall.item(), precision.item(), f1.mean().item(), ndcg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sampling - Recall@10: 0.0015180769842118025, Precision@10: 0.0009567197412252426, F1@10: 0.001173727447167039, ndcg : 0.012397877871990204\n"
     ]
    }
   ],
   "source": [
    "# def random_sampling_performance(test_items, num_items, k, device):\n",
    "#     # 랜덤 점수 생성\n",
    "#     random_scores = torch.rand(test_items.size(0), num_items).to(device)\n",
    "#     _, topk_indices = torch.topk(random_scores, k=k, dim=1)\n",
    "#     return topk_indices\n",
    "\n",
    "def random_sampling_performance(test_items, num_items, k, device):\n",
    "    # 랜덤 점수 생성\n",
    "    random_scores = torch.rand(test_items.size(0), num_items, device=device)\n",
    "    recall, precision, f1, ndcg = compute_metrics_for_random(random_scores, test_items, k, device)\n",
    "    return recall, precision, f1, ndcg\n",
    "\n",
    "num_items = preprocess.num_items  # 아이템의 총 수\n",
    "recall, precision, f1, ndcg = random_sampling_performance(\n",
    "    torch.FloatTensor(preprocess.user_item_matrix.toarray()).to(device), \n",
    "    num_items, \n",
    "    10,  # 상위 10개 아이템\n",
    "    device\n",
    ")\n",
    "print(f\"Random Sampling - Recall@10: {recall}, Precision@10: {precision}, F1@10: {f1}, ndcg : {ndcg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sampling - Recall@10: 0.0008287232485599816, Precision@10: 0.0004555808554869145, F1@10: 0.000587940972764045, NDCG: 0.006483666133135557\n",
      "Randomly selected item indexes: [1897 4111 1386 1354 6396 3466 4512 2583  578 3926]\n",
      "Randomly selected product IDs: ['B00N1SZXSM', 'B015K193WY', 'B00K808HAM', 'B00K2XPFEQ', 'B01H2CZ9Y0', 'B0108TSNDS', 'B017OFB8WC', 'B00SM0FDZ2', 'B00DM05DAW', 'B014I5CIOS']\n"
     ]
    }
   ],
   "source": [
    "# def random_sampling_performance_with_ids(test_items, item_encoder, num_items, k, device):\n",
    "#     # 전체 아이템 목록에서 랜덤하게 k개의 아이템 인덱스를 선택\n",
    "#     random_idx = torch.randint(0, num_items, (k,), device=device)\n",
    "    \n",
    "#     # 실제 테스트 아이템에 대해 선택된 랜덤 아이템 인덱스의 존재 여부 확인\n",
    "#     selected_items_mask = torch.zeros(test_items.size(0), num_items, device=device)\n",
    "#     selected_items_mask[:, random_idx] = 1  # 선택된 인덱스에 1을 할당\n",
    "\n",
    "#     # 선택된 랜덤 아이템을 기반으로 성능 메트릭 계산\n",
    "#     recall, precision, f1, ndcg = compute_metrics_for_random(selected_items_mask, test_items, k, device)\n",
    "\n",
    "#     return recall, precision, f1, ndcg, random_idx.cpu().numpy()\n",
    "\n",
    "# # 함수 실행 및 랜덤 아이템 선정 결과 출력\n",
    "# recall, precision, f1, ndcg, random_product_idxs = random_sampling_performance_with_ids(\n",
    "#     torch.FloatTensor(preprocess.user_item_matrix.toarray()).to(device), \n",
    "#     preprocess.item_encoder,  # 아이템 인코더\n",
    "#     preprocess.num_items,  # 아이템의 총 수\n",
    "#     10,  # 상위 10개 아이템\n",
    "#     device\n",
    "# )\n",
    "\n",
    "# print(f\"Random Sampling - Recall@10: {recall}, Precision@10: {precision}, F1@10: {f1}, NDCG: {ndcg}\")\n",
    "# # 랜덤으로 선택된 아이템 인덱스 출력\n",
    "# print(f\"Randomly selected item indexes: {random_product_idxs}\")\n",
    "# # 실제 product_id로 변환\n",
    "# random_product_ids = [preprocess.item_decoder[idx] for idx in random_product_idxs]\n",
    "# print(f\"Randomly selected product IDs: {random_product_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/home/siyun/ephemeral/lightgcn/data/'\n",
    "# data = pd.read_csv(data_path + 'rating_4_and_1.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B009MA34NY', 'B005AGO4LU', 'B010RRWKT4', 'B0092UF54A', 'B014IBJKNO', 'B0014F7B98', 'B0058YEJ5K', 'B001IKJOLW', 'B000YFSR5G', 'B000YFSR4W']\n",
      "idcg : tensor([3.5616, 4.2619, 3.5616,  ..., 2.5616, 2.9485, 2.5616], device='cuda:0')\n",
      "Top 10 Products - Recall@10: 0.17086172103881836, Precision@10: 0.12856492400169373, F1@10: 0.14672592282295227, ndcg : 0.15018948912620544\n"
     ]
    }
   ],
   "source": [
    "# `product_id` 별로 선택된 횟수 계산\n",
    "data_path = '/home/siyun/ephemeral/lightgcn/data/'\n",
    "data = pd.read_csv(data_path + 'rating_4_and_1_col_change.csv')\n",
    "  \n",
    "product_counts = data['product_id'].value_counts()\n",
    "# print(product_counts)\n",
    "\n",
    "# 가장 많이 선택된 `product_id` 10개\n",
    "top_10_products = product_counts.index[:10].tolist()\n",
    "print(top_10_products)\n",
    "product_id2idx = {id: idx for idx, id in enumerate(top_10_products)}\n",
    "\n",
    "#기존 1\n",
    "# def evaluate_top_products_performance(top_products, test_items, k, device):\n",
    "#     # 인기 제품의 인덱스를 기반으로 실제 테스트 세트에 포함되어 있는지 여부를 확인\n",
    "#     top_products_mask = torch.zeros_like(test_items).float()\n",
    "#     hits = 0\n",
    "#     total = test_items.sum().item()\n",
    "    \n",
    "#     for product_id in top_products:\n",
    "#         product_idx = product_id2idx.get(product_id)\n",
    "#         if product_idx is not None:\n",
    "#             top_products_mask += (test_items == product_idx).float()\n",
    "#     # top_products_mask를 사용하여 성능 평가\n",
    "#     return compute_metrics_for_random(top_products_mask, test_items, k, device)\n",
    "\n",
    "# 다시1\n",
    "# def evaluate_top_products_performance(top_products, test_items, k, device, item_encoder):\n",
    "#     # top_products 내 각 product_id에 대한 실제 인덱스를 찾기\n",
    "#     top_product_idxs = [item_encoder[product_id] for product_id in top_products if product_id in item_encoder]\n",
    "    \n",
    "\n",
    "#     # 실제 테스트 아이템에 대해 top_product_idxs의 존재 여부를 확인\n",
    "#     top_products_mask = torch.zeros(test_items.size(0), len(top_product_idxs), device=device)\n",
    "    \n",
    "#     for idx, product_idx in enumerate(top_product_idxs):\n",
    "#         top_products_mask[:, idx] = test_items[:, product_idx]\n",
    "\n",
    "#     # top_products_mask를 사용하여 실제 테스트 아이템에 포함된 인기 제품 수 계산\n",
    "#     hits = top_products_mask.sum().item()\n",
    "#     total_possible_hits = test_items.size(0) * min(k, len(top_product_idxs))\n",
    "    \n",
    "#     recall = hits / total_possible_hits\n",
    "#     precision = hits / (len(top_product_idxs) * test_items.size(0))\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall + 1e-8) if (precision + recall) > 0 else 0\n",
    "    \n",
    "#     # NDCG 계산은 이 경우에는 적용되지 않음 (또는 별도로 계산 필요)\n",
    "#     ndcg = 0\n",
    "\n",
    "#     return recall, precision, f1, ndcg\n",
    "\n",
    "\n",
    "# 다시 2\n",
    "\n",
    "def evaluate_top_products_performance(top_products, test_items, k, device, item_encoder):\n",
    "    # top_products 내 각 product_id에 대한 실제 인덱스를 찾기\n",
    "    top_product_idxs = [item_encoder.get(product_id, None) for product_id in top_products]\n",
    "    top_product_idxs = [idx for idx in top_product_idxs if idx is not None]\n",
    "\n",
    "    # top_products의 인덱스에 해당하는 예측 점수를 생성\n",
    "    pred_items = torch.zeros(test_items.size(0), test_items.size(1), device=device)\n",
    "    for idx in top_product_idxs:\n",
    "        pred_items[:, idx] = 1.0  # 인기 제품에 대한 점수를 1로 설정\n",
    "\n",
    "    _, topk_indices = torch.topk(pred_items, k=k, dim=1)\n",
    "    topk_preds = torch.zeros_like(pred_items).float()\n",
    "    topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "    # Recall@k: (TP) / (TP + FN)\n",
    "    tp = (test_items * topk_preds).sum(1)\n",
    "    recall = (tp / test_items.sum(1)).mean()\n",
    "\n",
    "    # Precision@k: (TP) / (TP + FP)\n",
    "    precision = (tp / k).mean()\n",
    "\n",
    "\n",
    "    # F1 Score: 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)  # NaN 값 처리\n",
    "\n",
    "\n",
    "    # NDCG 계산\n",
    "    log_pos = torch.log2(torch.arange(2, k+2, device=device).float())\n",
    "    log_pos_expanded = log_pos.unsqueeze(0).expand(test_items.size(0), -1)\n",
    "\n",
    "    relevant_scores = torch.gather(test_items, 1, topk_indices)\n",
    "    dcg = (relevant_scores / log_pos).sum(dim=1)\n",
    "\n",
    "    _, sorted_indices = torch.sort(test_items, dim=1, descending=True)\n",
    "    ideal_scores = torch.gather(test_items, 1, sorted_indices)[:, :k]\n",
    "    idcg = (ideal_scores / log_pos).sum(dim=1)\n",
    "    print(f\"idcg : {idcg}\")\n",
    "    idcg[idcg == 0] = 1e-8  # 0으로 나누는 것을 방지\n",
    "    ndcg = (dcg / idcg).mean()\n",
    "\n",
    "    return recall.item(), precision.item(), f1.item(), ndcg.item()\n",
    "\n",
    "item_encoder = preprocess.item_encoder\n",
    "\n",
    "recall_top, precision_top, f1_top, ndcg = evaluate_top_products_performance(\n",
    "    top_10_products,\n",
    "    torch.FloatTensor(preprocess.user_item_matrix.toarray()).to(device),\n",
    "    10,  # 상위 10개 아이템\n",
    "    device,\n",
    "    item_encoder\n",
    ")\n",
    "\n",
    "print(f\"Top 10 Products - Recall@10: {recall_top}, Precision@10: {precision_top}, F1@10: {f1_top}, ndcg : {ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8587"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = '/home/siyun/ephemeral/LightGCN_Recommender/data/'\n",
    "# data = pd.read_csv(data_path + 'filtered_data.csv')\n",
    "# data['product_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (user_embedding): Embedding(2195, 64)\n",
       "  (item_embedding): Embedding(6484, 64)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: New best model saved with F1: 0.2274\n",
      "Recall@10: 0.2861240804195404, Precision@10: 0.1886104792356491, f1: 0.2273523211479187, ndcg@10 : 0.26523298025131226, cosine : 0.41673028469085693, ILD : 0.5774409174919128,  trade_off : 0.3262515962123871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: New best model saved with F1: 0.2299\n",
      "Recall@10: 0.28973251581192017, Precision@10: 0.1905239224433899, f1: 0.22988125681877136, ndcg@10 : 0.27377381920814514, cosine : 0.4173014461994171, ILD : 0.5944643616676331,  trade_off : 0.3315507769584656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: New best model saved with F1: 0.2478\n",
      "Recall@10: 0.3162004053592682, Precision@10: 0.20369020104408264, f1: 0.24777106940746307, ndcg@10 : 0.30062663555145264, cosine : 0.4175242483615875, ILD : 0.6202173233032227,  trade_off : 0.3540874719619751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: New best model saved with F1: 0.2554\n",
      "Recall@10: 0.32646113634109497, Precision@10: 0.20970386266708374, f1: 0.25536975264549255, ndcg@10 : 0.3049313426017761, cosine : 0.41872042417526245, ILD : 0.6004480123519897,  trade_off : 0.3583385646343231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: New best model saved with F1: 0.2566\n",
      "Recall@10: 0.32776743173599243, Precision@10: 0.21088838577270508, f1: 0.256647527217865, ndcg@10 : 0.31593653559684753, cosine : 0.4198525547981262, ILD : 0.5818547010421753,  trade_off : 0.3561864495277405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: New best model saved with F1: 0.2703\n",
      "Recall@10: 0.3479887843132019, Precision@10: 0.2209567129611969, f1: 0.27029111981391907, ndcg@10 : 0.3308470845222473, cosine : 0.4209963083267212, ILD : 0.6477338671684265,  trade_off : 0.3814203441143036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.34663641452789307, Precision@10: 0.22022779285907745, f1: 0.2693377733230591, ndcg@10 : 0.32992640137672424, cosine : 0.4229480028152466, ILD : 0.6130778193473816,  trade_off : 0.37425678968429565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: New best model saved with F1: 0.2820\n",
      "Recall@10: 0.3647404909133911, Precision@10: 0.22979497909545898, f1: 0.28195300698280334, ndcg@10 : 0.359437495470047, cosine : 0.4247424900531769, ILD : 0.6207695603370667,  trade_off : 0.387777715921402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: New best model saved with F1: 0.3033\n",
      "Recall@10: 0.3936389982700348, Precision@10: 0.24674257636070251, f1: 0.3033425807952881, ndcg@10 : 0.3920848071575165, cosine : 0.4261576235294342, ILD : 0.6326585412025452,  trade_off : 0.41006848216056824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: New best model saved with F1: 0.3104\n",
      "Recall@10: 0.40337836742401123, Precision@10: 0.25220954418182373, f1: 0.31036531925201416, ndcg@10 : 0.40183135867118835, cosine : 0.427913099527359, ILD : 0.6360276937484741,  trade_off : 0.4171648323535919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3930870294570923, Precision@10: 0.24601365625858307, f1: 0.30262768268585205, ndcg@10 : 0.3892669975757599, cosine : 0.4292571544647217, ILD : 0.6074292063713074,  trade_off : 0.40398550033569336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: New best model saved with F1: 0.3218\n",
      "Recall@10: 0.41978535056114197, Precision@10: 0.26086562871932983, f1: 0.32177305221557617, ndcg@10 : 0.4191402792930603, cosine : 0.4305473268032074, ILD : 0.633538007736206,  trade_off : 0.42678341269493103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: New best model saved with F1: 0.3336\n",
      "Recall@10: 0.4362933337688446, Precision@10: 0.2699772119522095, f1: 0.3335527777671814, ndcg@10 : 0.43093380331993103, cosine : 0.4324464201927185, ILD : 0.6446740627288818,  trade_off : 0.4396379590034485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: New best model saved with F1: 0.3343\n",
      "Recall@10: 0.43737825751304626, Precision@10: 0.27052393555641174, f1: 0.3342871069908142, ndcg@10 : 0.4292082190513611, cosine : 0.43402713537216187, ILD : 0.6345565915107727,  trade_off : 0.43789127469062805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.39460188150405884, Precision@10: 0.24555808305740356, f1: 0.30272960662841797, ndcg@10 : 0.3802398443222046, cosine : 0.4369826316833496, ILD : 0.5364323258399963,  trade_off : 0.38703837990760803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.273507684469223, Precision@10: 0.18118451535701752, f1: 0.21797321736812592, ndcg@10 : 0.2403700053691864, cosine : 0.4458226263523102, ILD : 0.28379446268081665,  trade_off : 0.24656666815280914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3018576204776764, Precision@10: 0.19662870466709137, f1: 0.2381364107131958, ndcg@10 : 0.28074806928634644, cosine : 0.4485854208469391, ILD : 0.3398359417915344,  trade_off : 0.2800386846065521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.30140420794487, Precision@10: 0.19630980491638184, f1: 0.23776143789291382, ndcg@10 : 0.2903873324394226, cosine : 0.4515240788459778, ILD : 0.41046568751335144,  trade_off : 0.30110716819763184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3283766806125641, Precision@10: 0.21088837087154388, f1: 0.25683408975601196, ndcg@10 : 0.3264370858669281, cosine : 0.4521487057209015, ILD : 0.44168758392333984,  trade_off : 0.3248014748096466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3532783091068268, Precision@10: 0.2236446589231491, f1: 0.273897260427475, ndcg@10 : 0.35273975133895874, cosine : 0.4536949694156647, ILD : 0.4633307456970215,  trade_off : 0.34427616000175476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.36917516589164734, Precision@10: 0.2321184277534485, f1: 0.2850266993045807, ndcg@10 : 0.3693165183067322, cosine : 0.45511600375175476, ILD : 0.4821133315563202,  trade_off : 0.35825315117836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.36277472972869873, Precision@10: 0.22856491804122925, f1: 0.2804397642612457, ndcg@10 : 0.35898154973983765, cosine : 0.4566560685634613, ILD : 0.47596275806427,  trade_off : 0.35293084383010864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3803793489933014, Precision@10: 0.23817768692970276, f1: 0.2929329574108124, ndcg@10 : 0.382392942905426, cosine : 0.4575607478618622, ILD : 0.4975361227989197,  trade_off : 0.368755042552948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.39539268612861633, Precision@10: 0.24592256546020508, f1: 0.30323928594589233, ndcg@10 : 0.3936353325843811, cosine : 0.4587456285953522, ILD : 0.5202628970146179,  trade_off : 0.3831541836261749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.35435330867767334, Precision@10: 0.22387242317199707, f1: 0.2743908762931824, ndcg@10 : 0.35336509346961975, cosine : 0.45939111709594727, ILD : 0.4791412651538849,  trade_off : 0.34894856810569763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4121735692024231, Precision@10: 0.2552163898944855, f1: 0.3152383267879486, ndcg@10 : 0.4078519642353058, cosine : 0.46026578545570374, ILD : 0.535204291343689,  trade_off : 0.3967743217945099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4233155846595764, Precision@10: 0.26173120737075806, f1: 0.3234666585922241, ndcg@10 : 0.40719443559646606, cosine : 0.46184226870536804, ILD : 0.5463249683380127,  trade_off : 0.406345397233963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: New best model saved with F1: 0.3372\n",
      "Recall@10: 0.44292452931404114, Precision@10: 0.2722095549106598, f1: 0.337190717458725, ndcg@10 : 0.4298350214958191, cosine : 0.4622642993927002, ILD : 0.589012861251831,  trade_off : 0.42886826395988464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: New best model saved with F1: 0.3437\n",
      "Recall@10: 0.4523605704307556, Precision@10: 0.2770842909812927, f1: 0.34366410970687866, ndcg@10 : 0.4473329484462738, cosine : 0.462776243686676, ILD : 0.5667935013771057,  trade_off : 0.4278872013092041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4006355106830597, Precision@10: 0.25070616602897644, f1: 0.3084150552749634, ndcg@10 : 0.38684672117233276, cosine : 0.46356815099716187, ILD : 0.4845629632472992,  trade_off : 0.3769247233867645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.404047429561615, Precision@10: 0.25120729207992554, f1: 0.3098021447658539, ndcg@10 : 0.3975365459918976, cosine : 0.465616911649704, ILD : 0.5030444264411926,  trade_off : 0.38345304131507874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.441998690366745, Precision@10: 0.2722095549106598, f1: 0.3369220793247223, ndcg@10 : 0.4379187524318695, cosine : 0.46609821915626526, ILD : 0.5317092537879944,  trade_off : 0.4124755263328552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.40099504590034485, Precision@10: 0.24974943697452545, f1: 0.30779603123664856, ndcg@10 : 0.38928404450416565, cosine : 0.46804147958755493, ILD : 0.4253443479537964,  trade_off : 0.35714665055274963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.3845730721950531, Precision@10: 0.24159452319145203, f1: 0.29676002264022827, ndcg@10 : 0.3744712769985199, cosine : 0.4730665683746338, ILD : 0.4437335431575775,  trade_off : 0.3556611239910126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.41282525658607483, Precision@10: 0.25708431005477905, f1: 0.316851407289505, ndcg@10 : 0.4146716892719269, cosine : 0.47370660305023193, ILD : 0.47648724913597107,  trade_off : 0.38060835003852844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.41175755858421326, Precision@10: 0.2555352747440338, f1: 0.31535953283309937, ndcg@10 : 0.3935696482658386, cosine : 0.47421202063560486, ILD : 0.49099254608154297,  trade_off : 0.38404855132102966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.41174042224884033, Precision@10: 0.25585421919822693, f1: 0.315597265958786, ndcg@10 : 0.39576655626296997, cosine : 0.4742485582828522, ILD : 0.5125572681427002,  trade_off : 0.3906557559967041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.42848148941993713, Precision@10: 0.2646469175815582, f1: 0.3272014260292053, ndcg@10 : 0.4155873954296112, cosine : 0.47482430934906006, ILD : 0.5203746557235718,  trade_off : 0.40177473425865173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4344456195831299, Precision@10: 0.2678815424442291, f1: 0.3314124047756195, ndcg@10 : 0.4277324080467224, cosine : 0.47610440850257874, ILD : 0.5356171727180481,  trade_off : 0.4094673991203308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4378160536289215, Precision@10: 0.27020499110221863, f1: 0.3341710865497589, ndcg@10 : 0.42996934056282043, cosine : 0.47663095593452454, ILD : 0.5444677472114563,  trade_off : 0.4141528308391571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4397262930870056, Precision@10: 0.2708428204059601, f1: 0.3352149724960327, ndcg@10 : 0.43668943643569946, cosine : 0.47727689146995544, ILD : 0.5592222809791565,  trade_off : 0.4191678762435913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.447967529296875, Precision@10: 0.2750341594219208, f1: 0.34081903100013733, ndcg@10 : 0.43863967061042786, cosine : 0.47869324684143066, ILD : 0.5485888719558716,  trade_off : 0.42043596506118774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: New best model saved with F1: 0.3452\n",
      "Recall@10: 0.45362722873687744, Precision@10: 0.278542160987854, f1: 0.3451504707336426, ndcg@10 : 0.4490987956523895, cosine : 0.48042798042297363, ILD : 0.560064971446991,  trade_off : 0.4270954132080078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.44372519850730896, Precision@10: 0.27230069041252136, f1: 0.3374924659729004, ndcg@10 : 0.44041189551353455, cosine : 0.48074430227279663, ILD : 0.5589113831520081,  trade_off : 0.4208557903766632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: New best model saved with F1: 0.3561\n",
      "Recall@10: 0.46868792176246643, Precision@10: 0.28715264797210693, f1: 0.3561200201511383, ndcg@10 : 0.4666652977466583, cosine : 0.482117235660553, ILD : 0.5636096596717834,  trade_off : 0.43646013736724854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: New best model saved with F1: 0.3766\n",
      "Recall@10: 0.49627357721328735, Precision@10: 0.3034623861312866, f1: 0.3766252100467682, ndcg@10 : 0.4930812418460846, cosine : 0.4832591712474823, ILD : 0.5726152062416077,  trade_off : 0.4543871283531189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.49590644240379333, Precision@10: 0.3028701841831207, f1: 0.3760632574558258, ndcg@10 : 0.4983411729335785, cosine : 0.484240859746933, ILD : 0.5635664463043213,  trade_off : 0.4511067271232605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.48035746812820435, Precision@10: 0.29348519444465637, f1: 0.36435776948928833, ndcg@10 : 0.4728507697582245, cosine : 0.48537981510162354, ILD : 0.5521425008773804,  trade_off : 0.43901219964027405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.4803867042064667, Precision@10: 0.2929840683937073, f1: 0.3639797866344452, ndcg@10 : 0.473136842250824, cosine : 0.4864576458930969, ILD : 0.5603971481323242,  trade_off : 0.4413204491138458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 256/256 [00:16<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.390554815530777, Precision@10: 0.2450113743543625, f1: 0.30111852288246155, ndcg@10 : 0.3675791323184967, cosine : 0.4892670512199402, ILD : 0.45717567205429077,  trade_off : 0.36308878660202026\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 평가\n",
    "best_f1 = 0\n",
    "for epoch in range(1, config[\"num_epochs\"] + 1):\n",
    "    train_loss = train(\n",
    "        model=model,\n",
    "        make_graph_data_set=preprocess,\n",
    "        optimizer=optimizer,\n",
    "        n_batch=config[\"n_batch\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    recall, precision, f1, ndcg, ILD, trade_off = evaluate(model, \n",
    "                                       preprocess.user_item_matrix, \n",
    "                                       preprocess.user_item_matrix, \n",
    "                                       k=10, \n",
    "                                       device=device)\n",
    "\n",
    "    u_embeddings = model.user_embedding.weight\n",
    "    index = user_cosine(u_embeddings)\n",
    "\n",
    "    cosine = random_cosine(index, u_embeddings, ratio=1.0)\n",
    "\n",
    "    if best_f1 < f1:\n",
    "        best_f1 = f1\n",
    "        model_save_path = config[\"model_path\"]\n",
    "        if not os.path.exists(model_save_path):\n",
    "            os.mkdir(model_save_path)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path, config[\"model_name\"]))\n",
    "        print(f\"Epoch {epoch}: New best model saved with F1: {best_f1:.4f}\")\n",
    "\n",
    "    print(f\"Recall@10: {recall}, Precision@10: {precision}, f1: {f1}, ndcg@10 : {ndcg}, cosine : {cosine}, ILD : {ILD},  trade_off : {trade_off}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference관련\n",
    "- 0316 해야할 일\n",
    "- 추천받은 아이템이 실제 유저가 산 히스토리의 아이템과 유사한지 확인(완전 같지는 않아도 괜찮음)\n",
    "    - ex) 가방 -> 가방, 신발 -> 신발\n",
    "- 어느정도 나오는 것은 확인함\n",
    "\n",
    "## 추천과정\n",
    "- lightgcn -> 유저와 아이템간의 히스토리를 바탕으로 유저의 행동패턴에 대한 학습\n",
    "- 새로운 유저 -> 기존의 행동패턴이 비슷한 유저들을 반환\n",
    "- 그 유저들이 산 아이템을 하나로 합친 후 k개 반환\n",
    "    - 이렇게 한 이유 : Lightgcn의 학습 방식은 item을 반환하는 것이 아닌 유저와 아이템간의 상호작용에 대한 확률을 계산\n",
    "    - 결과적으로는 유저가 반환됨.\n",
    "    - 그렇기 때문에 비슷한 행동패턴을 보이는 유저는 비슷한 아이템을 샀을 것이라 가정 -> 그 유저들이 산 아이템들을 추천하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tm1897/mlg_cs224w_project/tree/main\n",
    "\n",
    "def load_model(model_path, model, device):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def encode_session_items(preprocess, session_items):\n",
    "    # 새로운 사용자 세션의 아이템을 인코딩\n",
    "    encoded_items = [preprocess.item_encoder[item] for item in session_items if item in preprocess.item_encoder]\n",
    "    return encoded_items\n",
    "\n",
    "def infer_embeddings(model, encoded_session_items, num_users, num_items, device):\n",
    "    # 모든 사용자와 아이템의 임베딩을 계산\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = model.compute_embeddings()\n",
    "        user_embeddings = all_embeddings[:num_users]\n",
    "        item_embeddings = all_embeddings[num_users:]\n",
    "\n",
    "        # 새로운 사용자 세션의 아이템 임베딩을 평균내어 사용자 임베딩을 대체\n",
    "        if encoded_session_items:\n",
    "            print(f\"if encoded_session_items : 1\")\n",
    "            session_item_embeddings = item_embeddings[encoded_session_items].mean(dim=0).unsqueeze(0)\n",
    "        else:\n",
    "            # 세션에 아이템이 없는 경우 무작위 사용자 임베딩 사용\n",
    "            print(f\"if not encoded_session_items : 2\")\n",
    "            session_item_embeddings = user_embeddings[torch.randint(0, num_users, (1,))]\n",
    "    return session_item_embeddings, item_embeddings, user_embeddings\n",
    "\n",
    "def recommend_item(session_user_embedding, item_embeddings, top_k):\n",
    "    # 사용자 임베딩과 모든 아이템 임베딩 간의 유사도를 계산\n",
    "    scores = torch.matmul(session_user_embedding, item_embeddings.T)\n",
    "    top_scores, top_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "    return top_indices.squeeze().tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def recommend_users(session_item_embeddings, user_embeddings, top_k):\n",
    "    # 세션 사용자 임베딩과 모든 사용자 임베딩 간의 유사도를 계산\n",
    "    scores = torch.matmul(session_item_embeddings, user_embeddings.T)\n",
    "    top_scores, top_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "    return top_indices.squeeze().tolist()\n",
    "\n",
    "\n",
    "\n",
    "def random_item(recommended_user_ids, data, k) : \n",
    "    # 유사한 사용자의 아이템 추천 받기\n",
    "    total_items = []\n",
    "    for user_id in recommended_user_ids:\n",
    "        # 여기서는 'product_id' 대신 실제 data에서 사용하는 상호작용 아이템 컬럼명을 사용하세요.\n",
    "        user_items = data[data['user_id'] == user_id]['product_id'].tolist()\n",
    "        total_items.extend(user_items)\n",
    "\n",
    "\n",
    "    # 고유 아이템 선택\n",
    "    unique_items = list(set(total_items))\n",
    "\n",
    "    recommended_items = random.sample(unique_items, k) if len(unique_items) >= k else unique_items\n",
    "    return recommended_items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/siyun/ephemeral/LightGCN_Recommender/data/'\n",
    "data = pd.read_csv(data_path + 'filtered_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 많은 item_id를 구매한 user_id: A3G5KDMFNRUXHB\n"
     ]
    }
   ],
   "source": [
    "# user_item_counts = data.groupby('user_id')['item_id'].count()\n",
    "# # item_id 개수가 가장 많은 user_id 찾기\n",
    "# most_frequent_user_id = user_item_counts.idxmax()\n",
    "# print(\"가장 많은 item_id를 구매한 user_id:\", most_frequent_user_id)\n",
    "# list(data[data['user_id'] == 'A3G5KDMFNRUXHB'].item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 데이터 로드\n",
    "model_path = config[\"model_path\"] + '/' + config[\"model_name\"]\n",
    "model = LightGCN(num_users, num_items, config['emb_dim'], config['n_layers'], config['reg'], adjacency_matrix, device)\n",
    "model = load_model(model_path, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B00JO5MTXI',\n",
       " 'B00LD84PGS',\n",
       " 'B00OR6KCAQ',\n",
       " 'B00S60V1RW',\n",
       " 'B00W6TY12Q',\n",
       " 'B01CKX5Y4Q']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[data['user_id'] == 'A0986263H7SX62P1SRDD']['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아이템 추천의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_session_items: [0, 1, 2, 3, 4, 5]\n",
      "if encoded_session_items : 1\n",
      "recommended_user : ['B000YFSR5G', 'B000YFSR4W', 'B00KA3VO3O', 'B00S99PCSE', 'B00KW4LCCE', 'B00UDF11O6', 'B00KA3VEG6', 'B00LMU7GHM', 'B00KA3WMJY', 'B000K2PJ4K']\n"
     ]
    }
   ],
   "source": [
    "# 새로운 유저 입력\n",
    "session_items = ['B00JO5MTXI',\n",
    " 'B00LD84PGS',\n",
    " 'B00OR6KCAQ',\n",
    " 'B00S60V1RW',\n",
    " 'B00W6TY12Q',\n",
    " 'B01CKX5Y4Q']\n",
    "\n",
    "# 새로운 유저의 입력을 받아서 인코딩\n",
    "encoded_session_items = encode_session_items(preprocess, session_items)\n",
    "print(f\"encoded_session_items: {encoded_session_items}\")\n",
    "\n",
    "# 사용자와 아이템의 임베딩 계산\n",
    "session_user_embedding, item_embeddings, _ = infer_embeddings(model, encoded_session_items, num_users, num_items, device)\n",
    "\n",
    "# 유사한 아이템 행동패턴을 보이는 유저 반환\n",
    "top_k = 10  # 행동 확률이 높은 K명의 유저 반환\n",
    "recommended_user_indices = recommend_item(session_user_embedding, item_embeddings, top_k)\n",
    "\n",
    "\n",
    "# 모델의 구조 상 유사한 유저의 아이템 목록이 아닌 유사한 행동패턴을 가진 유저가 반환\n",
    "recommended_user = [preprocess.item_decoder[idx] for idx in recommended_user_indices if idx in preprocess.item_decoder]\n",
    "print(f\"recommended_user : {recommended_user}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사한 유저 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if encoded_session_items : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B005GPKRV6',\n",
       " 'B00OAZOMMI',\n",
       " 'B00IZ61MU8',\n",
       " 'B00KTEO274',\n",
       " 'B01E5GNWMW',\n",
       " 'B015GXCM5G',\n",
       " 'B00FYU9THG',\n",
       " 'B00P1XXR6A',\n",
       " 'B000YFSR5G',\n",
       " 'B00MSC158E']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids = data['user_id'].unique()\n",
    "id2idx = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "idx2id = {idx: user_id for user_id, idx in id2idx.items()}\n",
    "\n",
    "\n",
    "\n",
    "session_items = ['B00JO5MTXI',\n",
    " 'B00LD84PGS',\n",
    " 'B00OR6KCAQ',\n",
    " 'B00S60V1RW',\n",
    " 'B00W6TY12Q',\n",
    " 'B01CKX5Y4Q']\n",
    "\n",
    "\n",
    "\n",
    "# 새로운 유저의 입력을 받아서 인코딩\n",
    "encoded_session_items = encode_session_items(preprocess, session_items)\n",
    "# 사용자와 아이템의 임베딩 계산\n",
    "session_user_embedding, item_embeddings, user_embeddings = infer_embeddings(model, encoded_session_items, num_users, num_items, device)\n",
    "\n",
    "# 유사한 사용자 찾기\n",
    "top_k_users = 15  # 행동 패턴이 유사한 상위 K명의 사용자\n",
    "# id2idx가 반환됨\n",
    "recommended_user_indices = recommend_users(session_user_embedding, user_embeddings, top_k_users)\n",
    "# idx2id\n",
    "recommended_user_ids = [idx2id[idx] for idx in recommended_user_indices]\n",
    "\n",
    "random_item(recommended_user_ids,data,top_k_users)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 유사한 사용자의 아이템 추천 받기\n",
    "# total_items = []\n",
    "# for user_id in recommended_user_ids:\n",
    "#     # 여기서는 'product_id' 대신 실제 data에서 사용하는 상호작용 아이템 컬럼명을 사용하세요.\n",
    "#     user_items = data[data['user_id'] == user_id]['product_id'].tolist()\n",
    "#     total_items.extend(user_items)\n",
    "\n",
    "\n",
    "# # 고유 아이템 선택\n",
    "# unique_items = list(set(total_items))\n",
    "\n",
    "# recommended_items = random.sample(unique_items, top_k_users) if len(unique_items) >= top_k_users else unique_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B005GPKRV6',\n",
       " 'B00OAZOMMI',\n",
       " 'B00IZ61MU8',\n",
       " 'B00KTEO274',\n",
       " 'B01E5GNWMW',\n",
       " 'B015GXCM5G',\n",
       " 'B00FYU9THG',\n",
       " 'B00P1XXR6A',\n",
       " 'B000YFSR5G',\n",
       " 'B00MSC158E']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['B00JO5MTXI',\n",
    " 'B00LD84PGS',\n",
    " 'B00OR6KCAQ',\n",
    " 'B00S60V1RW',\n",
    " 'B00W6TY12Q',\n",
    " 'B01CKX5Y4Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg',\n",
       " 'https://images-na.ssl-images-amazon.com/images/I/51yCQvuWSnL.jpg']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['product_id'] =='B000K2PJ4K']['image_url'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
