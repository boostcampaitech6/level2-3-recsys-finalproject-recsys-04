{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1413763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1411862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1408924800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1408838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1406419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883631</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>A1ZSB2Q144UTEY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1487635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883632</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>A2CCDV0J5VB6F2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1480032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883633</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>A3O90PACS7B61K</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1478736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883634</th>\n",
       "      <td>B01HJHF97K</td>\n",
       "      <td>A2HO94I89U3LNH</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1478736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883635</th>\n",
       "      <td>B01HJG5NMW</td>\n",
       "      <td>A2RSX9E79DUHRX</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1470700800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883636 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  rating  unixReviewTime\n",
       "0       7106116521  A1D4G1SNUZWQOT     5.0      1413763200\n",
       "1       7106116521  A3DDWDH9PX2YX2     2.0      1411862400\n",
       "2       7106116521  A2MWC41EW7XL15     4.0      1408924800\n",
       "3       7106116521  A2UH2QQ275NV45     2.0      1408838400\n",
       "4       7106116521   A89F3LQADZBS5     3.0      1406419200\n",
       "...            ...             ...     ...             ...\n",
       "883631  B01HJHTH5U  A1ZSB2Q144UTEY     5.0      1487635200\n",
       "883632  B01HJHTH5U  A2CCDV0J5VB6F2     5.0      1480032000\n",
       "883633  B01HJHTH5U  A3O90PACS7B61K     3.0      1478736000\n",
       "883634  B01HJHF97K  A2HO94I89U3LNH     3.0      1478736000\n",
       "883635  B01HJG5NMW  A2RSX9E79DUHRX     5.0      1470700800\n",
       "\n",
       "[883636 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('./data/AMAZON_FASHION.csv', names=['asin','reviewerID','rating','unixReviewTime'])\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상품 unique :  186189\n",
      "리뷰어 unique :  749233\n"
     ]
    }
   ],
   "source": [
    "print(\"상품 unique : \", df_ratings['asin'].nunique())\n",
    "print(\"리뷰어 unique : \", df_ratings['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0764443682</td>\n",
       "      <td>Slime Time Fall Fest [With CDROM and Collector...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291691480</td>\n",
       "      <td>XCC Qi promise new spider snake preparing men'...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1940280001</td>\n",
       "      <td>Magical Things I Really Do Do Too!</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1940735033</td>\n",
       "      <td>Ashes to Ashes, Oranges to Oranges</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940967805</td>\n",
       "      <td>Aether &amp; Empire #1 - 2016 First Printing Comic...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186632</th>\n",
       "      <td>B01HJGXL4O</td>\n",
       "      <td>JT Women's Elegant Off Shoulder Chiffon Maxi L...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186633</th>\n",
       "      <td>B01HJHF97K</td>\n",
       "      <td>Microcosm Retro Vintage Black Crochet Lace One...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186634</th>\n",
       "      <td>B01HJGJ9LS</td>\n",
       "      <td>Lookatool Classic Plain Vintage Army Military ...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186635</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>Edith Windsor Women's Deep V-neck Beaded Sequi...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186636</th>\n",
       "      <td>B01HJFNU7S</td>\n",
       "      <td>Aeropostale Women's Sun &amp; Waves Crop Cami L Gr...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132017 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                              title  \\\n",
       "0       0764443682  Slime Time Fall Fest [With CDROM and Collector...   \n",
       "1       1291691480  XCC Qi promise new spider snake preparing men'...   \n",
       "2       1940280001                 Magical Things I Really Do Do Too!   \n",
       "3       1940735033                 Ashes to Ashes, Oranges to Oranges   \n",
       "4       1940967805  Aether & Empire #1 - 2016 First Printing Comic...   \n",
       "...            ...                                                ...   \n",
       "186632  B01HJGXL4O  JT Women's Elegant Off Shoulder Chiffon Maxi L...   \n",
       "186633  B01HJHF97K  Microcosm Retro Vintage Black Crochet Lace One...   \n",
       "186634  B01HJGJ9LS  Lookatool Classic Plain Vintage Army Military ...   \n",
       "186635  B01HJHTH5U  Edith Windsor Women's Deep V-neck Beaded Sequi...   \n",
       "186636  B01HJFNU7S  Aeropostale Women's Sun & Waves Crop Cami L Gr...   \n",
       "\n",
       "                                          imageURLHighRes  \n",
       "0       [https://images-na.ssl-images-amazon.com/image...  \n",
       "1       [https://images-na.ssl-images-amazon.com/image...  \n",
       "2       [https://images-na.ssl-images-amazon.com/image...  \n",
       "3       [https://images-na.ssl-images-amazon.com/image...  \n",
       "4       [https://images-na.ssl-images-amazon.com/image...  \n",
       "...                                                   ...  \n",
       "186632  [https://images-na.ssl-images-amazon.com/image...  \n",
       "186633  [https://images-na.ssl-images-amazon.com/image...  \n",
       "186634  [https://images-na.ssl-images-amazon.com/image...  \n",
       "186635  [https://images-na.ssl-images-amazon.com/image...  \n",
       "186636  [https://images-na.ssl-images-amazon.com/image...  \n",
       "\n",
       "[132017 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_json('./data/meta_AMAZON_FASHION.json', lines=True)\n",
    "df_meta = df_meta[['asin','title','imageURLHighRes']]\n",
    "# imageURLHighRes가 있는 row들만 필터링\n",
    "df_meta = df_meta[~df_meta['imageURLHighRes'].isna()]\n",
    "# df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48898    Colorful Peacock Bird Wing Y Bib Collar Necklace\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta[df_meta['asin'] == 'B00KW4LCCE']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[df_ratings['reviewerID'] == 'A3G5KDMFNRUXHB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rating & meta data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rating table 평점 5개 이상인 유저만 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'reviewerID' 기준으로 5 이상인 값을 가지는 유저를 필터링\n",
    "## 3개로 진행해서 다시 test\n",
    "reviewer_counts = df_ratings['reviewerID'].value_counts()\n",
    "reviewer_filter = reviewer_counts[reviewer_counts >= 5].index # 5 이상으로 필터링하기로 협의\n",
    "\n",
    "# 필터링 조건을 만족하는 데이터 추출\n",
    "filtered_df = df_ratings[df_ratings['reviewerID'].isin(reviewer_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상품 unique :  13197\n",
      "리뷰어 unique :  3718\n"
     ]
    }
   ],
   "source": [
    "print(\"상품 unique : \", filtered_df['asin'].nunique())\n",
    "print(\"리뷰어 unique : \", filtered_df['reviewerID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 배열에서 동일한 값: ['7106116521' 'B00008JPRZ' 'B00012O2RY' ... 'B01HJEOBUO' 'B01HJG5NLI'\n",
      " 'B01HJGJ9LS']\n",
      "동일한 값의 개수: 10681\n"
     ]
    }
   ],
   "source": [
    "# rating이 5개 이상인 유저로 필터링된 데이터에서 이미지 url이 존재하는 아이템이 있는지 메타데이터에서 동일한 값 찾기\n",
    "common_values = np.intersect1d(df_meta['asin'].unique(), filtered_df['asin'].unique())\n",
    "\n",
    "# 동일한 값의 개수 확인\n",
    "num_common_values = len(common_values)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"두 배열에서 동일한 값:\", common_values)\n",
    "print(\"동일한 값의 개수:\", num_common_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터에서 rating데이터와 공통으로 존재하는 아이템을 필터링\n",
    "df_meta_filtered = df_meta[df_meta['asin'].isin(common_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge inner\n",
    "df_meta_rating = pd.merge(df_meta_filtered, filtered_df)\n",
    "df_meta_rating = df_meta_rating[df_meta_rating['rating'] >= 4.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin               0\n",
       "title              0\n",
       "imageURLHighRes    0\n",
       "reviewerID         0\n",
       "rating             0\n",
       "unixReviewTime     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan값 확인\n",
    "df_meta_rating.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID\n",
       "A3JBQHQZEZPQK4    33\n",
       "A1RRX286ZRI830    24\n",
       "ALFRMOGTO1K4M     22\n",
       "A3CZ0K3S0BXHKE    21\n",
       "AENH50GW3OKDA     20\n",
       "                  ..\n",
       "A2E1QSIUA6H0XW     1\n",
       "A1USW773RKOSKG     1\n",
       "A1DU6H3WIN1G0T     1\n",
       "A3T5H74TOGU049     1\n",
       "A2Y0U0RAIFFART     1\n",
       "Name: count, Length: 3556, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_rating['reviewerID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta_rating merge 한 것에서 다시 reviewerID가 5 이상인 것들로 필터링\n",
    "df_meta_rating_counts = df_meta_rating['reviewerID'].value_counts()\n",
    "df_meta_rating_filter = df_meta_rating_counts[df_meta_rating_counts >=4].index\n",
    "filtered_df_meta_rating = df_meta_rating[df_meta_rating['reviewerID'].isin(df_meta_rating_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12690, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_meta_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_meta_rating.to_csv('/home/siyun/ephemeral/lightgcn/data/rating_filtered_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상품 unique :  6484\n",
      "리뷰어 unique :  2195\n",
      "sparsity :  0.999108371193012\n"
     ]
    }
   ],
   "source": [
    "print(\"상품 unique : \", filtered_df_meta_rating['asin'].nunique())\n",
    "print(\"리뷰어 unique : \", filtered_df_meta_rating['reviewerID'].nunique())\n",
    "print(f\"sparsity :  {1-len(filtered_df_meta_rating) / (filtered_df_meta_rating['asin'].nunique()*filtered_df_meta_rating['reviewerID'].nunique()):.15f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_meta_rating.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1857144/1673943722.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df_meta_rating['rating'] = 1\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "# 1. rating 값을 1로 전부 변환\n",
    "filtered_df_meta_rating['rating'] = 1\n",
    "# 모델 input으로 사용할 column\n",
    "df_input = filtered_df_meta_rating[['asin','reviewerID','rating', 'unixReviewTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>AD0OENWU7N4L6</td>\n",
       "      <td>1</td>\n",
       "      <td>1437436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00008JPRZ</td>\n",
       "      <td>A281NL3AO4QIGE</td>\n",
       "      <td>1</td>\n",
       "      <td>1508630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00008JPRZ</td>\n",
       "      <td>A281NL3AO4QIGE</td>\n",
       "      <td>1</td>\n",
       "      <td>1508630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0001F331C</td>\n",
       "      <td>A2M1IZTVL7TMC0</td>\n",
       "      <td>1</td>\n",
       "      <td>1352937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0001F331C</td>\n",
       "      <td>A2M1IZTVL7TMC0</td>\n",
       "      <td>1</td>\n",
       "      <td>1352937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20769</th>\n",
       "      <td>B01HHSZEQC</td>\n",
       "      <td>A2FV2M9MG76NB7</td>\n",
       "      <td>1</td>\n",
       "      <td>1483401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20772</th>\n",
       "      <td>B01HI84VBA</td>\n",
       "      <td>AZD378NGJIDQH</td>\n",
       "      <td>1</td>\n",
       "      <td>1471824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20775</th>\n",
       "      <td>B01HIRHI2K</td>\n",
       "      <td>A2UU7363R2ESCN</td>\n",
       "      <td>1</td>\n",
       "      <td>1506902400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20778</th>\n",
       "      <td>B01HJEOBUO</td>\n",
       "      <td>A21DXQFAP5TTHY</td>\n",
       "      <td>1</td>\n",
       "      <td>1471219200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20779</th>\n",
       "      <td>B01HJG5NLI</td>\n",
       "      <td>A2HOQJXDFZP9Y7</td>\n",
       "      <td>1</td>\n",
       "      <td>1470182400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin      reviewerID  rating  unixReviewTime\n",
       "0      7106116521   AD0OENWU7N4L6       1      1437436800\n",
       "1      B00008JPRZ  A281NL3AO4QIGE       1      1508630400\n",
       "2      B00008JPRZ  A281NL3AO4QIGE       1      1508630400\n",
       "5      B0001F331C  A2M1IZTVL7TMC0       1      1352937600\n",
       "6      B0001F331C  A2M1IZTVL7TMC0       1      1352937600\n",
       "...           ...             ...     ...             ...\n",
       "20769  B01HHSZEQC  A2FV2M9MG76NB7       1      1483401600\n",
       "20772  B01HI84VBA   AZD378NGJIDQH       1      1471824000\n",
       "20775  B01HIRHI2K  A2UU7363R2ESCN       1      1506902400\n",
       "20778  B01HJEOBUO  A21DXQFAP5TTHY       1      1471219200\n",
       "20779  B01HJG5NLI  A2HOQJXDFZP9Y7       1      1470182400\n",
       "\n",
       "[12690 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.to_csv('/home/siyun/ephemeral/BERT4Rec/data/rating4_bert.csv', index=False)\n",
    "\n",
    "df_input.to_csv('/home/siyun/ephemeral/lightgcn/data/rating_4_and_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6484"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.asin.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2195"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.reviewerID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6484,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = df_input['asin'].unique()\n",
    "user_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set:\n",
      "             asin      reviewerID  rating  unixReviewTime\n",
      "12060  B00V5BV778   AD0OENWU7N4L6       1      1436400000\n",
      "1282   B0015ZD6HI   AD0OENWU7N4L6       1      1311638400\n",
      "0      7106116521   AD0OENWU7N4L6       1      1437436800\n",
      "4241   B009PMJZUA   AD0OENWU7N4L6       1      1365552000\n",
      "2      B00008JPRZ  A281NL3AO4QIGE       1      1508630400\n",
      "...           ...             ...     ...             ...\n",
      "19487  B01EJ333P2   AE4AXSBD2GBRI       1      1467936000\n",
      "20098  B01FV2C23E   AE4AXSBD2GBRI       1      1467936000\n",
      "20198  B01G2K47JQ   AWSSM21BOTF5P       1      1486339200\n",
      "20194  B01G2K2YBE   AWSSM21BOTF5P       1      1471219200\n",
      "20197  B01G2K458Y   AWSSM21BOTF5P       1      1471219200\n",
      "\n",
      "[10433 rows x 4 columns]\n",
      "\n",
      "Test set:\n",
      "             asin      reviewerID  rating  unixReviewTime\n",
      "1281   B0015ZD6HI   AD0OENWU7N4L6       1      1311638400\n",
      "1      B00008JPRZ  A281NL3AO4QIGE       1      1508630400\n",
      "6      B0001F331C  A2M1IZTVL7TMC0       1      1352937600\n",
      "1537   B001BFLRU0  A3FOL5CECUQJKV       1      1259452800\n",
      "8      B0006HB4XE  A2XG05RVALZZSA       1      1394755200\n",
      "...           ...             ...     ...             ...\n",
      "19148  B01DWBI9WY  A3CMY6YN374VD1       1      1466208000\n",
      "19232  B01E3HBIVK  A2BLP5XDO3MJ5R       1      1470787200\n",
      "19332  B01E88OUOG  A2XBCZI83UO70I       1      1463356800\n",
      "19511  B01EKS0796   AE4AXSBD2GBRI       1      1470096000\n",
      "20195  B01G2K4BR4   AWSSM21BOTF5P       1      1471219200\n",
      "\n",
      "[2257 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 각 사용자별로 데이터를 분할하기 위해 사용자 리스트 생성\n",
    "user_list = df_input['reviewerID'].unique()\n",
    "\n",
    "# 각 사용자별로 train, validation, test set으로 나누기\n",
    "train_data = pd.DataFrame()\n",
    "# valid_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for user_id in user_list:\n",
    "    user_data = df_input[df_input['reviewerID'] == user_id]\n",
    "    # train_user, temp_user = train_test_split(user_data, test_size=0.4, random_state=42)\n",
    "    # valid_user, test_user = train_test_split(temp_user, test_size=0.5, random_state=42)\n",
    "    train_user, test_user = train_test_split(user_data, test_size=0.1, random_state=42)\n",
    "    # print(train_user)\n",
    "\n",
    "    train_data = pd.concat([train_data, train_user])\n",
    "    # valid_data = pd.concat([valid_data, valid_user])\n",
    "    test_data = pd.concat([test_data, test_user])\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\nTrain set:\")\n",
    "print(train_data)\n",
    "# print(\"\\nValidation set:\")\n",
    "# print(valid_data)\n",
    "print(\"\\nTest set:\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset csv로 저장\n",
    "train_data.to_csv('./data/rating_trainset_amazon_fashion_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset csv로 저장\n",
    "test_data.to_csv('./data/rating_testset_amazon_fashion_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EASE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TorchEASE:\n",
    "    def __init__(\n",
    "        self, train, user_col=\"user_id\", item_col=\"item_id\", score_col=None, reg=300\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param train: Training DataFrame of user, item, score(optional) values\n",
    "        :param user_col: Column name for users\n",
    "        :param item_col: Column name for items\n",
    "        :param score_col: Column name for scores. Implicit feedback otherwise\n",
    "        :param reg: Regularization parameter\n",
    "        \"\"\"\n",
    "        logging.basicConfig(\n",
    "            format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "            level=logging.INFO,\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "            stream=sys.stdout,\n",
    "        )\n",
    "\n",
    "        self.logger = logging.getLogger(\"notebook\")\n",
    "        self.logger.info(\"Building user + item lookup\")\n",
    "        # How much regularization do you need?\n",
    "        self.reg = reg\n",
    "\n",
    "        self.user_col = user_col\n",
    "        self.item_col = item_col\n",
    "\n",
    "        self.user_id_col = user_col + \"_id\"\n",
    "        self.item_id_col = item_col + \"_id\"\n",
    "\n",
    "        self.user_lookup = self.generate_labels(train, self.user_col)\n",
    "        self.item_lookup = self.generate_labels(train, self.item_col)\n",
    "\n",
    "        self.item_map = {}\n",
    "        self.logger.info(\"Building item hashmap\")\n",
    "        for _item, _item_id in self.item_lookup.values:\n",
    "            self.item_map[_item_id] = _item\n",
    "\n",
    "        train = pd.merge(train, self.user_lookup, on=[self.user_col])\n",
    "        train = pd.merge(train, self.item_lookup, on=[self.item_col])\n",
    "        self.logger.info(\"User + item lookup complete\")\n",
    "        self.indices = torch.LongTensor(\n",
    "            train[[self.user_id_col, self.item_id_col]].values\n",
    "        )\n",
    "\n",
    "        if not score_col:\n",
    "            # Implicit values only\n",
    "            self.values = torch.ones(self.indices.shape[0])\n",
    "        else:\n",
    "            self.values = torch.FloatTensor(train[score_col])\n",
    "        # TODO: Is Sparse the best implementation?\n",
    "\n",
    "        self.sparse = torch.sparse.FloatTensor(self.indices.t(), self.values)\n",
    "\n",
    "        self.logger.info(\"Sparse data built\")\n",
    "\n",
    "    def generate_labels(self, df, col):\n",
    "        dist_labels = df[[col]].drop_duplicates()\n",
    "        dist_labels[col + \"_id\"] = dist_labels[col].astype(\"category\").cat.codes\n",
    "\n",
    "        return dist_labels\n",
    "\n",
    "    def fit(self):\n",
    "        self.logger.info(\"Building G Matrix\")\n",
    "        self.G = self.sparse.to_dense().t() @ self.sparse.to_dense()\n",
    "        self.G += torch.eye(self.G.shape[0]) * self.reg\n",
    "\n",
    "        self.P = self.G.inverse()\n",
    "\n",
    "        self.logger.info(\"Building B matrix\")\n",
    "        B = self.P / (-1 * self.P.diag())\n",
    "        # Set diagonals to 0. TODO: Use .fill_diag_\n",
    "        B = B + torch.eye(B.shape[0])\n",
    "\n",
    "        # Predictions for user `_u` will be self.sparse.to_dense()[_u]@self.B\n",
    "        self.B = B\n",
    "\n",
    "        return\n",
    "\n",
    "    def fine_tune(self, new_data):\n",
    "        \"\"\"\n",
    "        Fine-tune the model with new data.\n",
    "\n",
    "        :param new_data: New training DataFrame of user, item, score(optional) values\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Fine-tuning model with new data\")\n",
    "\n",
    "        # Update indices and values with new data\n",
    "        new_user_ids = self.generate_labels(new_data, self.user_col)\n",
    "        new_item_ids = self.generate_labels(new_data, self.item_col)\n",
    "\n",
    "        new_data = pd.merge(new_data, new_user_ids, on=[self.user_col])\n",
    "        new_data = pd.merge(new_data, new_item_ids, on=[self.item_col])\n",
    "\n",
    "        new_indices = torch.LongTensor(new_data[[self.user_id_col, self.item_id_col]].values)\n",
    "\n",
    "\n",
    "        new_values = torch.ones(new_indices.shape[0])\n",
    "      \n",
    "\n",
    "        # Update sparse matrix\n",
    "        self.indices = torch.cat((self.indices, new_indices), dim=0)\n",
    "        self.values = torch.cat((self.values, new_values), dim=0)\n",
    "        self.sparse = torch.sparse.FloatTensor(self.indices.t(), self.values)\n",
    "\n",
    "        # Update user lookup\n",
    "        new_user_lookup = self.generate_labels(new_data, self.user_col)\n",
    "        self.user_lookup = pd.concat([self.user_lookup, new_user_lookup]).drop_duplicates()\n",
    "\n",
    "        # Re-calculate G matrix\n",
    "        self.logger.info(\"Updating G Matrix\")\n",
    "        new_data_tensor = torch.sparse.FloatTensor(self.indices.t(), self.values)\n",
    "        G_update = torch.matmul(new_data_tensor.to_dense().t(), new_data_tensor.to_dense())\n",
    "        G_update += torch.eye(G_update.shape[0]) * self.reg\n",
    "\n",
    "        # Ensure G_update has the same size as self.G\n",
    "        if G_update.shape != self.G.shape:\n",
    "            self.logger.error(\"Shape mismatch between G_update and self.G\")\n",
    "            print(\"G_update.shape\", G_update.shape)\n",
    "            print(\"self.G.shape\", self.G.shape)\n",
    "            return\n",
    "\n",
    "        self.G = G_update\n",
    "\n",
    "        # Re-calculate B matrix\n",
    "        self.logger.info(\"Updating B Matrix\")\n",
    "        P = self.G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B += torch.eye(B.shape[0])\n",
    "        self.B = B\n",
    "\n",
    "        self.logger.info(\"Fine-tuning complete.\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict_all(self, pred_df, k=5, remove_owned=True):\n",
    "        \"\"\"\n",
    "        :param pred_df: DataFrame of users that need predictions\n",
    "        :param k: Number of items to recommend to each user\n",
    "        :param remove_owned: Do you want previously interacted items included?\n",
    "        :return: DataFrame of users + their predictions in sorted order\n",
    "        \"\"\"\n",
    "        pred_df = pred_df[[self.user_col]].drop_duplicates()\n",
    "        n_orig = pred_df.shape[0]\n",
    "\n",
    "        # Alert to number of dropped users in prediction set\n",
    "        pred_df = pd.merge(pred_df, self.user_lookup, on=[self.user_col])\n",
    "        n_curr = pred_df.shape[0]\n",
    "        if n_orig - n_curr:\n",
    "            self.logger.info(\n",
    "                \"Number of unknown users from prediction data = %i\" % (n_orig - n_curr)\n",
    "            )\n",
    "\n",
    "        _output_preds = []\n",
    "        # Select only user_ids in our user data\n",
    "        _user_tensor = self.sparse.to_dense().index_select(\n",
    "            dim=0, index=torch.LongTensor(pred_df[self.user_id_col])\n",
    "        )\n",
    "\n",
    "        # Make our (raw) predictions\n",
    "        _preds_tensor = _user_tensor @ self.B\n",
    "        self.logger.info(\"Predictions are made\")\n",
    "        if remove_owned:\n",
    "            # Discount these items by a large factor (much faster than list comp.)\n",
    "            self.logger.info(\"Removing owned items\")\n",
    "            _preds_tensor += -1.0 * _user_tensor\n",
    "\n",
    "        self.logger.info(\"TopK selected per user\")\n",
    "        for _preds in _preds_tensor:\n",
    "            # Very quick to use .topk() vs. argmax()\n",
    "            _output_preds.append(\n",
    "                [self.item_map[_id] for _id in _preds.topk(k).indices.tolist()]\n",
    "            )\n",
    "\n",
    "        pred_df[\"predicted_items\"] = _output_preds\n",
    "        self.logger.info(\"Predictions are returned to user\")\n",
    "        return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(ground_truth, predicted_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Recall@k\n",
    "    Parameters:\n",
    "        ground_truth (dict): 실제 사용자 평가 데이터. {userid: [itemid1, itemid2, ...]}\n",
    "        predicted_items (dict): 모델이 예측한 아이템 목록. {userid: [predicted_itemid1, predicted_itemid2, ...]}\n",
    "        k (int): 상위 k개의 예측 아이템을 사용하여 Recall 계산\n",
    "    Returns:\n",
    "        recall (float): Recall@k\n",
    "    \"\"\"\n",
    "    total_recall = 0\n",
    "    total_users = len(ground_truth)\n",
    "\n",
    "    for user_id, true_items in ground_truth.items():\n",
    "        predicted = predicted_items.get(user_id, [])[:k]\n",
    "        true_positives = len(set(predicted) & set(true_items))\n",
    "        total_recall += true_positives / len(true_items) if len(true_items) > 0 else 0\n",
    "\n",
    "    recall = total_recall / total_users\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ground_truth,predicted_items, k=10):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        ground_truth (_type_): _description_\n",
    "        predicted_items (_type_): _description_\n",
    "        k (int, optional): _description_. Defaults to 10.\n",
    "    Returns :\n",
    "        precision\n",
    "    \"\"\"\n",
    "    total_precision = 0\n",
    "    total_users = len(ground_truth)\n",
    "    \n",
    "    for user_id, true_items in ground_truth.items() :\n",
    "        predicted = predicted_items.get(user_id, [])[:k]\n",
    "        true_positives = len(set(predicted) & set(true_items))\n",
    "        total_precision += true_positives / k if k > 0 else 0\n",
    "        \n",
    "    precision = total_precision / total_users\n",
    "    return precision\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(ground_truth,predicted_items, k=10) :\n",
    "    recall = recall_at_k(ground_truth,predicted_items, k)\n",
    "    precision = precision_at_k(ground_truth,predicted_items, k)\n",
    "    \n",
    "    if precision + recall > 0 :\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else :\n",
    "        f1_score = 0\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dcg_at_k(r,k) :\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size :\n",
    "        return np.sum(r/np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(ground_truth,predicted_items, k=10) :\n",
    "    total_ndcg = 0\n",
    "    total_users = len(ground_truth)\n",
    "    \n",
    "    for user, true_items in ground_truth.items() :\n",
    "        predicted = predicted_items.get(user, [])[:k]\n",
    "        ideal = dcg_at_k(sorted([1 if item in true_items else 0 for item in predicted],reverse=True),k)\n",
    "        actual_dcg = dcg_at_k([1 if item in true_items else 0 for item in predicted], k)\n",
    "        total_ndcg += (actual_dcg / ideal) if ideal > 0 else 0\n",
    "\n",
    "    ndcg = total_ndcg / total_users\n",
    "    return ndcg\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def calculate_diversity_ease(predicted_items, item_vectors):\n",
    "    vectors = [item_vectors[item] for item in predicted_items if item in item_vectors]\n",
    "    if len(vectors) < 2:\n",
    "        return 0\n",
    "\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    # 상위 삼각행렬의 값만 추출하여 평균 유사도 계산\n",
    "    upper_triangle_indices = np.triu_indices_from(similarity_matrix, k=1)\n",
    "    avg_similarity = np.mean(similarity_matrix[upper_triangle_indices])\n",
    "    \n",
    "    diversity = 1 - avg_similarity\n",
    "    \n",
    "    return diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-26 17:38:43 [INFO] notebook - Building user + item lookup\n",
      "2024-03-26 17:38:43 [INFO] notebook - Building item hashmap\n",
      "2024-03-26 17:38:43 [INFO] notebook - User + item lookup complete\n",
      "2024-03-26 17:38:43 [INFO] notebook - Sparse data built\n"
     ]
    }
   ],
   "source": [
    "model = TorchEASE(train_data, user_col=\"reviewerID\", item_col=\"asin\", reg=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-26 17:38:46 [INFO] notebook - Building G Matrix\n",
      "2024-03-26 17:38:48 [INFO] notebook - Building B matrix\n",
      "CPU times: user 17.2 s, sys: 1.66 s, total: 18.9 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-26 17:38:50 [INFO] notebook - Predictions are made\n",
      "2024-03-26 17:38:50 [INFO] notebook - Removing owned items\n",
      "2024-03-26 17:38:50 [INFO] notebook - TopK selected per user\n",
      "2024-03-26 17:38:50 [INFO] notebook - Predictions are returned to user\n",
      "CPU times: user 4.3 s, sys: 298 ms, total: 4.59 s\n",
      "Wall time: 609 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model.predict_all(test_data, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'true_item_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m grouped \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewerID\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlist\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_item\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 원래 데이터프레임과 병합하여 새로운 true_item 컬럼을 추가\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrouped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviewerID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 데이터프레임을 딕셔너리로 변환\u001b[39;00m\n\u001b[1;32m      6\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewerID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto_dict()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_item\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/reshape/merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    149\u001b[0m         left,\n\u001b[1;32m    150\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/reshape/merge.py:811\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    809\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 811\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/reshape/merge.py:763\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    760\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    761\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 763\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    772\u001b[0m         join_index,\n\u001b[1;32m    773\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    779\u001b[0m     )\n",
      "File \u001b[0;32m~/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/reshape/merge.py:2640\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2638\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[0;32m-> 2640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2643\u001b[0m     )\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'true_item_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "# 중복되는 reviewerID를 가진 행을 그룹화하고 asin 값을 리스트로 수집하여 딕셔너리에 저장\n",
    "grouped = test_data.groupby('reviewerID')['asin'].apply(list).reset_index(name='true_item')\n",
    "# 원래 데이터프레임과 병합하여 새로운 true_item 컬럼을 추가\n",
    "test_data = pd.merge(test_data, grouped, on='reviewerID', how='left')\n",
    "# 데이터프레임을 딕셔너리로 변환\n",
    "result_dict = test_data.set_index('reviewerID').to_dict()['true_item']\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pred = out.set_index('reviewerID').to_dict()['predicted_items']\n",
    "# result_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 0.19047076689445708, precision : 0.019362186788155048, f1 : 0.03515110950467661, ndcg : 0.1740839062171303\n"
     ]
    }
   ],
   "source": [
    "# Recall@10 계산\n",
    "predicted_items = result_pred\n",
    "ground_truth = result_dict\n",
    "recall = recall_at_k(ground_truth, predicted_items, k=10)\n",
    "precision = precision_at_k(ground_truth, predicted_items, k=10)\n",
    "f1 = f1_score(ground_truth, predicted_items, k=10)\n",
    "ndcg = ndcg_at_k(ground_truth, predicted_items, k=10)\n",
    "\n",
    "print(f\"recall : {recall}, precision : {precision}, f1 : {f1}, ndcg : {ndcg}\")\n",
    "\n",
    "\n",
    "# ease의 경우는 item vector로 임베딩화 시킨 후 계싼해야함.\n",
    "# b = model.B\n",
    "# calculate_diversity_ease(predicted_items, item_vectors)\n",
    "\n",
    "# print(f\"diversity : {diversity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B00LMUA8MC',\n",
       " 'B00LMUA6C4',\n",
       " 'B00KW4LCCE',\n",
       " 'B00LMU8WSE',\n",
       " 'B00E1L9QOU',\n",
       " 'B00LMU7WUI',\n",
       " 'B00KT1267K',\n",
       " 'B00KA3ROE2',\n",
       " 'B00LMU9NE6',\n",
       " 'B00KA3WMJY']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pred['A3G5KDMFNRUXHB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>B00VL50JXQ</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>B00NL59JSA</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>B00GWSXSEE</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>B01DXTQ3H8</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>B01H5XMDMC</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>B018FVB6LW</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>B00KREP4NW</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>B01AZ31G2C</td>\n",
       "      <td>A3G5KDMFNRUXHB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin      reviewerID\n",
       "1751  B00VL50JXQ  A3G5KDMFNRUXHB\n",
       "1752  B00NL59JSA  A3G5KDMFNRUXHB\n",
       "1753  B00GWSXSEE  A3G5KDMFNRUXHB\n",
       "1754  B01DXTQ3H8  A3G5KDMFNRUXHB\n",
       "1755  B01H5XMDMC  A3G5KDMFNRUXHB\n",
       "1756  B018FVB6LW  A3G5KDMFNRUXHB\n",
       "1757  B00KREP4NW  A3G5KDMFNRUXHB\n",
       "1758  B01AZ31G2C  A3G5KDMFNRUXHB"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[['asin','reviewerID']].loc[test_data['reviewerID']=='A3G5KDMFNRUXHB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = test_data[['asin','reviewerID']].loc[test_data['reviewerID']=='A2CFCXKCAWPIXQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data['reviewerID'] = 'A2CFCXKCAWPIXQ_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18545</th>\n",
       "      <td>B01CS4MRKQ</td>\n",
       "      <td>A2CFCXKCAWPIXQ_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18592</th>\n",
       "      <td>B01CV70HWU</td>\n",
       "      <td>A2CFCXKCAWPIXQ_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin           reviewerID\n",
       "18545  B01CS4MRKQ  A2CFCXKCAWPIXQ_test\n",
       "18592  B01CV70HWU  A2CFCXKCAWPIXQ_test"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 16:10:21 [INFO] notebook - Fine-tuning model with new data\n",
      "2024-03-16 16:10:21 [INFO] notebook - Updating G Matrix\n",
      "G_update.shape torch.Size([7060, 7060])\n",
      "self.G.shape torch.Size([7060, 7060])\n",
      "2024-03-16 16:10:22 [INFO] notebook - Updating B Matrix\n",
      "2024-03-16 16:10:25 [INFO] notebook - Fine-tuning complete.\n"
     ]
    }
   ],
   "source": [
    "model.fine_tune(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 16:14:14 [INFO] notebook - Predictions are made\n",
      "2024-03-16 16:14:14 [INFO] notebook - Removing owned items\n",
      "2024-03-16 16:14:14 [INFO] notebook - TopK selected per user\n",
      "2024-03-16 16:14:14 [INFO] notebook - Predictions are returned to user\n",
      "CPU times: user 95 ms, sys: 55.9 ms, total: 151 ms\n",
      "Wall time: 28.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp_new_result = model.predict_all(tmp_data, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 11:32:31 [INFO] notebook - Predictions are made\n",
      "2024-03-16 11:32:31 [INFO] notebook - Removing owned items\n",
      "2024-03-16 11:32:31 [INFO] notebook - TopK selected per user\n",
      "2024-03-16 11:32:31 [INFO] notebook - Predictions are returned to user\n",
      "CPU times: user 126 ms, sys: 61.9 ms, total: 188 ms\n",
      "Wall time: 48.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = model.predict_all(test_data[['asin','reviewerID']].loc[test_data['reviewerID']=='AD0OENWU7N4L6'], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B01DF878RQ',\n",
       " 'B01EXAVD3K',\n",
       " 'B01EMCB9QU',\n",
       " 'B01E7XRXKU',\n",
       " 'B01EU2YXQU',\n",
       " 'B01H1R4WLM',\n",
       " 'B01D37X10W',\n",
       " 'B00KTMIZQK',\n",
       " 'B019GGH8AI',\n",
       " 'B01799KAY0']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_items['A2CFCXKCAWPIXQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B00Q2M2C6A',\n",
       " 'B00YBZ0JRY',\n",
       " 'B00V5BV778',\n",
       " 'B0015ZD6HI',\n",
       " 'B00UDF11O6',\n",
       " 'B000PMKBL6',\n",
       " 'B003CTTFE8',\n",
       " 'B003CTREGO',\n",
       " 'B009PMJZUA',\n",
       " 'B00MIMOVB2']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_new_result['predicted_items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerID_id</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123456997</td>\n",
       "      <td>0</td>\n",
       "      <td>[B00Q2M2C6A, B00YBZ0JRY, B00V5BV778, B0015ZD6H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviewerID  reviewerID_id                                    predicted_items\n",
       "0  123456997              0  [B00Q2M2C6A, B00YBZ0JRY, B00V5BV778, B0015ZD6H..."
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerID_id</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123456999</td>\n",
       "      <td>0</td>\n",
       "      <td>[B00V5BV778, B0015ZD6HI, B009PMJZUA, B00Q2M2C6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviewerID  reviewerID_id                                    predicted_items\n",
       "0  123456999              0  [B00V5BV778, B0015ZD6HI, B009PMJZUA, B00Q2M2C6..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerID_id</th>\n",
       "      <th>predicted_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD0OENWU7N4L6</td>\n",
       "      <td>2134</td>\n",
       "      <td>[B00QI51L0O, B00SFPUDKO, B00M6SF3YW, B00BQHNKG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewerID  reviewerID_id  \\\n",
       "0  AD0OENWU7N4L6           2134   \n",
       "\n",
       "                                     predicted_items  \n",
       "0  [B00QI51L0O, B00SFPUDKO, B00M6SF3YW, B00BQHNKG...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,f'./save/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TorchEASE object at 0x7fd103b61c30>\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./save/model.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 11:07:05 [INFO] notebook - Predictions are made\n",
      "2024-03-16 11:07:05 [INFO] notebook - Removing owned items\n",
      "2024-03-16 11:07:05 [INFO] notebook - TopK selected per user\n",
      "2024-03-16 11:07:05 [INFO] notebook - Predictions are returned to user\n",
      "          reviewerID  reviewerID_id  \\\n",
      "0      AD0OENWU7N4L6           2134   \n",
      "1     A281NL3AO4QIGE            823   \n",
      "2     A3PSH91YKGP4IV           1808   \n",
      "3     A2M1IZTVL7TMC0           1090   \n",
      "4     A2XG05RVALZZSA           1287   \n",
      "...              ...            ...   \n",
      "2573  A2CFCXKCAWPIXQ            918   \n",
      "2574  A1BQC32PHYS1GG            234   \n",
      "2575  A3CMY6YN374VD1           1568   \n",
      "2576  A2BLP5XDO3MJ5R            905   \n",
      "2577   AE4AXSBD2GBRI           2148   \n",
      "\n",
      "                                        predicted_items  \n",
      "0     [B00QI51L0O, B00SFPUDKO, B00M6SF3YW, B00BQHNKG...  \n",
      "1     [B001LNSY2Q, B00P1XXR6A, B00OAZOMMI, B01B1TX3D...  \n",
      "2     [B00LMU7GHM, B00MIMOVB2, B00LMU8WSE, B00KW4LCC...  \n",
      "3     [B000AO7PY0, B000BD7SGK, B0007PRMT0, B0009NYJF...  \n",
      "4     [B00KA3VO3O, B00KW4LIJQ, B00KREP1HQ, B00MIMOVB...  \n",
      "...                                                 ...  \n",
      "2573  [B01DF878RQ, B01EXAVD3K, B01EMCB9QU, B01E7XRXK...  \n",
      "2574  [B01DF878RQ, B01E28Y3I0, B01E69YL4G, B01GQMIWQ...  \n",
      "2575  [B00MUC7O00, B01AML7B4O, B01EMCB9QU, B01E7XRXK...  \n",
      "2576  [B000AO7PY0, B000BD7SGK, B0007PRMT0, B0009NYJF...  \n",
      "2577  [B01ABO4RQC, B01FCZ7OE2, B01B185Z9K, B01DVQ0PC...  \n",
      "\n",
      "[2578 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "inputs = test_data\n",
    "outputs = model.predict_all(inputs,k=10)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##flow\n",
    "# 1. input -> 학습된 모델, 클라이언트가 선택한 item 리스트\n",
    "# 2. output -> top n개의 추천된 아이템\n",
    "\n",
    "##될까? 하는 것들\n",
    "# 1. 뭔가 지금 모델은 학습된 유저에 대해서만 predict이 가능한거 같은데.. -> 새로 들어온 데이터(클라이언트가 선택한 item 리스트)에 대해서 model.finetune을 구현해야할 듯.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_rec(model, input_ids, top_k):\n",
    "    top_k = int(top_k)\n",
    "\n",
    "    recommend_output = model.finetune(input_ids)\n",
    "\n",
    "    recommend_output = recommend_output[:, -1, :]\n",
    "    test_item_emb = model.item_embeddings.weight\n",
    "    rating_pred = torch.matmul(recommend_output, test_item_emb.transpose(0, 1))\n",
    "\n",
    "    rating_pred = rating_pred.cpu().data.numpy().copy()[0]\n",
    "\n",
    "    rating_pred[input_ids[0]] = 0\n",
    "\n",
    "    pred_ids = np.argsort(rating_pred)[::-1][:top_k]\n",
    "    df = pd.read_csv(\"poster.csv\", sep=\"\\t\")\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    return df[df[\"item\"].isin(pred_ids)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
