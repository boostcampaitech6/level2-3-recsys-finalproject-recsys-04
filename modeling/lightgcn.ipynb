{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siyun/ephemeral/miniconda3/envs/recbole/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# sparse 행렬을 만들어야 하기 때문에 다음과 같이 import\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import math\n",
    "import tqdm as tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from box import Box\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/gusye1234/LightGCN-PyTorch/blob/master/code/dataloader.py\n",
    "# https://github.com/SeongBeomLEE/RecsysTutorial/blob/main/LightGCN/LightGCN.ipynb\n",
    "# https://radish-greens.tistory.com/1\n",
    "## 참고하여 재정의\n",
    "\n",
    "class Preprocess :\n",
    "    def __init__(self, data_path, config) : \n",
    "        self.data = pd.read_csv(data_path, names=['user_id', 'item_id','rating','timestamp'], skiprows=1)\n",
    "        self.config = config\n",
    "        # bpr을 이용하기 때문에 encoder, decoder의 구조가 필요\n",
    "        ## 유저, 아이템 행렬에 대한 각각의 encoder, decoder가 필요\n",
    "        self.user_encoder, self.user_decoder, self.num_users = self._encode_user()\n",
    "        self.item_encoder, self.item_decoder, self.num_items = self._encode_item()\n",
    "\n",
    "        # 유저와 아이템의 관계에 대한 인접행렬 생산\n",
    "        #  build a graph in torch.sparse.IntTensor.\n",
    "        # Details in NGCF's matrix form\n",
    "        # A = \n",
    "        #     |I,   R|\n",
    "        #     |R^T, I|\n",
    "        # \"\"\"\n",
    "        self.user_item_matrix = self._generate_user_item_matrix()\n",
    "        self.adjacency_matrix = self._generate_adjacency_matrix() \n",
    "\n",
    "\n",
    "        self.exist_users = list(self.user_encoder.values())  # 혹은 다른 방식으로 존재하는 사용자 ID 목록 생성\n",
    "        self.exist_items = list(self.item_encoder.values())  # 존재하는 아이템 ID 목록\n",
    "        self.user_train = self._generate_user_train()  # 사용자별 긍정 아이템 목록을 생성하는 메서드 필요\n",
    "\n",
    "    def _encode_user(self) :\n",
    "        unique_users = self.data['user_id'].unique()\n",
    "        user_encoder = {user_id:idx for idx, user_id in enumerate(unique_users)}\n",
    "        user_decoder = {idx:user_id for user_id, idx in user_encoder.items()}\n",
    "        return user_encoder,user_decoder,len(unique_users)\n",
    "\n",
    "    def _encode_item(self) : \n",
    "        unique_items = self.data['item_id'].unique()\n",
    "        item_encoder = {item_id:idx for idx, item_id in enumerate(unique_items)}\n",
    "        item_decoder = {idx:item_id for item_id, idx in item_encoder.items()}\n",
    "        \n",
    "        return item_encoder,item_decoder,len(unique_items)\n",
    "\n",
    "    def _generate_user_item_matrix(self) :\n",
    "        # matrix에 들어갈 내용을 정합니다.\n",
    "        # rows, cols, value로 구성됨 \n",
    "        rows = self.data['user_id'].map(self.user_encoder)\n",
    "        cols = self.data['item_id'].map(self.item_encoder)\n",
    "        values = np.ones(len(self.data))\n",
    "        user_item_matrix = sp.csr_matrix((values, (rows,cols)), shape=(self.num_users, self.num_items))\n",
    "        return user_item_matrix\n",
    "\n",
    "    def _generate_adjacency_matrix(self) : \n",
    "        # user에 대한 그래프 + 아이템에 대한 그래프에 대한 인접그래프 생성\n",
    "        user_item_matrix = self.user_item_matrix\n",
    "        item_user_matrix = self.user_item_matrix.transpose()\n",
    "\n",
    "        zero_user_to_user = sp.csr_matrix((self.num_users, self.num_users))\n",
    "        zero_item_to_item = sp.csr_matrix((self.num_items, self.num_items))\n",
    "\n",
    "        # 상단 블록 (사용자-사용자 연결 및 사용자-아이템 연결)\n",
    "        upper_block = sp.hstack([zero_user_to_user, user_item_matrix], format='csr')\n",
    "        # 하단 블록 (아이템-사용자 연결 및 아이템-아이템 연결)\n",
    "        lower_block = sp.hstack([item_user_matrix, zero_item_to_item], format='csr')\n",
    "\n",
    "        adjacency_matrix = sp.vstack([upper_block, lower_block], format='csr')\n",
    "\n",
    "        return adjacency_matrix\n",
    "\n",
    "    def _generate_user_train(self) :\n",
    "        user_train = {}\n",
    "        for _, row in self.data.iterrows() :\n",
    "            user_id = self.user_encoder[row.user_id]\n",
    "            item_id = self.item_encoder[row.item_id]\n",
    "            if user_id not in user_train :\n",
    "                user_train[user_id] = []\n",
    "            user_train[user_id].append(item_id)\n",
    "        return user_train\n",
    "\n",
    "    def sampling(self):\n",
    "        users = random.sample(self.exist_users, self.config['n_batch'])\n",
    "\n",
    "        def sample_pos_items_for_u(u, num):\n",
    "            pos_items = self.user_train[u]\n",
    "            pos_batch = random.sample(pos_items, num)\n",
    "            return pos_batch\n",
    "\n",
    "        def sample_neg_items_for_u(u, num):\n",
    "            neg_items = list(set(self.exist_items) - set(self.user_train[u]))\n",
    "            neg_batch = random.sample(neg_items, num)\n",
    "            return neg_batch\n",
    "\n",
    "        pos_items, neg_items = [], []\n",
    "        for user in users:\n",
    "            pos_items += sample_pos_items_for_u(user, 1)\n",
    "            neg_items += sample_neg_items_for_u(user, 1)\n",
    "\n",
    "        return users, pos_items, neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/siyun/ephemeral/lightgcn/LightGCN-PyTorch/data/amazon/amazon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24139, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv(data_path, names=['user_id', 'item_id','rating','timestamp'], skiprows=1)\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightgcn의 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원저자와의 차이\n",
    "\n",
    "1. 모델 초기화 차이\n",
    "- xavier -> normal\n",
    "2. dropout 처리\n",
    "- 원저자 : dropout 생략\n",
    "- 내 구조 : 추가\n",
    "3. forward\n",
    "- 원저자 : graph convolution 직접 계산, 모든 layer의 임베딩을 평균 -> 최종 임베딩\n",
    "- 내 구조 : 간략한 계산\n",
    "4. loss function\n",
    "- 원저자 : BPR class 직접 사용\n",
    "    - 파라미터 업데이트에 사용되는 optimizer 관리\n",
    "- 내 구조 : BPR 직접계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, emb_dim, n_layers, reg, adj_mtx, device):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "        self.l = adj_mtx\n",
    "        self.graph = self._convert_sp_mat_to_sp_tensor(self.l)\n",
    "\n",
    "        self.reg = reg\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim).to(device)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=emb_dim).to(device)\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        torch.nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "        torch.nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "        self.adj_mtx = self._convert_sp_mat_to_sp_tensor(adj_mtx).to(device)\n",
    "        \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "        v = torch.FloatTensor(coo.data)\n",
    "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "        return res\n",
    "    def forward(self, user, pos_item, neg_item):\n",
    "        \"\"\"\n",
    "        Computes the forward pass\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "        user = user\n",
    "        pos_item = positive item (user interacted with item)\n",
    "        neg_item = negative item (user did not interact with item)\n",
    "        \"\"\"\n",
    "        \n",
    "        all_embeddings = self.compute_embeddings()\n",
    "        \n",
    "        u_embeddings = all_embeddings[:self.n_users]\n",
    "        i_embeddings = all_embeddings[self.n_users:]\n",
    "\n",
    "        users_emb = u_embeddings[user]\n",
    "        pos_emb = i_embeddings[pos_item]\n",
    "        neg_emb = i_embeddings[neg_item]\n",
    "\n",
    "        pos_scores = torch.sum(users_emb * pos_emb, dim=-1)\n",
    "        neg_scores = torch.sum(users_emb * neg_emb, dim=-1)\n",
    "\n",
    "        loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "        # Regularization term\n",
    "        if self.reg > 0:\n",
    "            reg_term = (1/2)*(users_emb.norm(2).pow(2) + \n",
    "                              pos_emb.norm(2).pow(2) + \n",
    "                              neg_emb.norm(2).pow(2))/float(len(user))\n",
    "            loss += self.reg * reg_term\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_embeddings(self):\n",
    "        users_emb = self.user_embedding.weight\n",
    "        items_emb = self.item_embedding.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb])\n",
    "\n",
    "        embs = [all_emb]\n",
    "        for _ in range(self.n_layers):\n",
    "            all_emb = torch.sparse.mm(self.adj_mtx, all_emb)\n",
    "            embs.append(all_emb)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        light_out = torch.mean(embs, dim=1)\n",
    "        return light_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LightGCN(nn.Module):\n",
    "#     # dropout 제거\n",
    "#     # def __init__(self, n_users, n_items, emb_dim, n_layers, reg, node_dropout, adj_mtx):\n",
    "#     def __init__(self, n_users, n_items, emb_dim, n_layers, reg, adj_mtx, device):\n",
    "#         super().__init__()\n",
    "#         # initialize Class attributes\n",
    "#         self.n_users = n_users\n",
    "#         self.n_items = n_items\n",
    "#         self.emb_dim = emb_dim\n",
    "        \n",
    "#         self.l = adj_mtx\n",
    "#         self.graph = self._convert_sp_mat_to_sp_tensor(self.l)\n",
    "\n",
    "#         self.reg = reg\n",
    "#         self.n_layers = n_layers\n",
    "#         self.device = device\n",
    "#         # --------------------------------\n",
    "#         # 제거\n",
    "#         # self.node_dropout = node_dropout\n",
    "\n",
    "#         # Initialize weights\n",
    "#         # self.weight_dict = self._init_weights()\n",
    "#         # print(\"Weights initialized.\")\n",
    "\n",
    "#     # # initialize weights\n",
    "#     # def _init_weights(self):\n",
    "#     #     print(\"Initializing weights...\")\n",
    "#     #     weight_dict = nn.ParameterDict()\n",
    "\n",
    "#     #     # initializer = torch.nn.init.xavier_uniform_\n",
    "#     #     initializer = torch.nn.init.normal_\n",
    "        \n",
    "#     #     weight_dict['user_embedding'] = nn.Parameter(initializer(torch.empty(self.n_users, self.emb_dim).to(device)))\n",
    "#     #     weight_dict['item_embedding'] = nn.Parameter(initializer(torch.empty(self.n_items, self.emb_dim).to(device)))\n",
    "\n",
    "#     #     return weight_dict\n",
    "#     # --------------------------------\n",
    "#         self.user_embedding = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=emb_dim).to(device)\n",
    "#         self.item_embedding = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=emb_dim).to(device)\n",
    "        \n",
    "#         # Initialize embeddings\n",
    "#         torch.nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "#         torch.nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "#         self.adj_mtx = self._convert_sp_mat_to_sp_tensor(adj_mtx).to(device)\n",
    "\n",
    "\n",
    "#     # convert sparse matrix into sparse PyTorch tensor\n",
    "#     def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "#         \"\"\"\n",
    "#         Convert scipy sparse matrix to PyTorch sparse matrix\n",
    "\n",
    "#         Arguments:\n",
    "#         ----------\n",
    "#         X = Adjacency matrix, scipy sparse matrix\n",
    "#         \"\"\"\n",
    "#         coo = X.tocoo().astype(np.float32)\n",
    "#         i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
    "#         v = torch.FloatTensor(coo.data)\n",
    "#         res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
    "#         return res\n",
    "#     # 드랍아웃을 사용하지 않는 경우 주석처리\n",
    "#     # apply node_dropout\n",
    "#     # def _droupout_sparse(self, X):\n",
    "#     #     \"\"\"\n",
    "#     #     Drop individual locations in X\n",
    "        \n",
    "#     #     Arguments:\n",
    "#     #     ---------\n",
    "#     #     X = adjacency matrix (PyTorch sparse tensor)\n",
    "#     #     dropout = fraction of nodes to drop\n",
    "#     #     noise_shape = number of non non-zero entries of X\n",
    "#     #     \"\"\"\n",
    "#     #     node_dropout_mask = ((self.node_dropout) + torch.rand(X._nnz())).floor().bool().to(device)\n",
    "#     #     i = X.coalesce().indices()\n",
    "#     #     v = X.coalesce()._values()\n",
    "#     #     i[:,node_dropout_mask] = 0\n",
    "#     #     v[node_dropout_mask] = 0\n",
    "#     #     X_dropout = torch.sparse.FloatTensor(i, v, X.shape).to(X.device)\n",
    "\n",
    "#     #     return  X_dropout.mul(1/(1-self.node_dropout))\n",
    "\n",
    "#     def forward(self, user, pos_item, neg_item):\n",
    "#         \"\"\"\n",
    "#         Computes the forward pass\n",
    "        \n",
    "#         Arguments:\n",
    "#         ---------\n",
    "#         user = user\n",
    "#         pos_item = positive item (user interacted with item)\n",
    "#         neg_item = negative item (user did not interact with item)\n",
    "#         \"\"\"\n",
    "        \n",
    "#         all_embeddings = self.compute_embeddings()\n",
    "        \n",
    "#         u_embeddings = all_embeddings[:self.n_users]\n",
    "#         i_embeddings = all_embeddings[self.n_users:]\n",
    "\n",
    "#         users_emb = u_embeddings[user]\n",
    "#         pos_emb = i_embeddings[pos_item]\n",
    "#         neg_emb = i_embeddings[neg_item]\n",
    "\n",
    "#         pos_scores = torch.sum(users_emb * pos_emb, dim=-1)\n",
    "#         neg_scores = torch.sum(users_emb * neg_emb, dim=-1)\n",
    "\n",
    "#         loss = -torch.mean(F.logsigmoid(pos_scores - neg_scores))\n",
    "\n",
    "#         # Regularization term\n",
    "#         if self.reg > 0:\n",
    "#             reg_term = (1/2)*(users_emb.norm(2).pow(2) + \n",
    "#                               pos_emb.norm(2).pow(2) + \n",
    "#                               neg_emb.norm(2).pow(2))/float(len(user))\n",
    "#             loss += self.reg * reg_term\n",
    "\n",
    "#         return loss\n",
    "\n",
    "#     def compute_embeddings(self):\n",
    "#         users_emb = self.user_embedding.weight\n",
    "#         items_emb = self.item_embedding.weight\n",
    "#         all_emb = torch.cat([users_emb, items_emb])\n",
    "\n",
    "#         embs = [all_emb]\n",
    "#         for _ in range(self.n_layers):\n",
    "#             all_emb = torch.sparse.mm(self.adj_mtx, all_emb)\n",
    "#             embs.append(all_emb)\n",
    "\n",
    "#         embs = torch.stack(embs, dim=1)\n",
    "#         light_out = torch.mean(embs, dim=1)\n",
    "#         return light_out\n",
    "#         # # apply drop-out mask\n",
    "#         # graph = self._droupout_sparse(self.graph) if self.node_dropout > 0 else self.graph\n",
    "#         # ego_embeddings = torch.cat([self.weight_dict['user_embedding'], self.weight_dict['item_embedding']], 0)\n",
    "#         # final_embeddings = [ego_embeddings]\n",
    "\n",
    "#         # for k in range(self.n_layers):\n",
    "#         #     ego_embeddings = torch.sparse.mm(graph, final_embeddings[k])\n",
    "#         #     final_embeddings.append(ego_embeddings)                                       \n",
    "\n",
    "#         # final_embeddings = torch.stack(final_embeddings, dim=1)\n",
    "#         # final_embeddings = torch.mean(final_embeddings, dim=1)\n",
    "        \n",
    "#         # u_final_embeddings, i_final_embeddings = final_embeddings.split([self.n_users, self.n_items], 0)\n",
    "\n",
    "#         # self.u_final_embeddings = nn.Parameter(u_final_embeddings)\n",
    "#         # self.i_final_embeddings = nn.Parameter(i_final_embeddings)\n",
    "        \n",
    "#         # # loss 계산\n",
    "#         # u_emb = u_final_embeddings[u] # user embeddings\n",
    "#         # p_emb = i_final_embeddings[i] # positive item embeddings\n",
    "#         # n_emb = i_final_embeddings[j] # negative item embeddings\n",
    "        \n",
    "#         # y_ui = torch.sum(torch.mul(u_emb, p_emb), dim = 1)                        \n",
    "#         # y_uj = torch.sum(torch.mul(u_emb, n_emb), dim = 1)\n",
    "        \n",
    "#         # log_prob = torch.mean(torch.log(torch.sigmoid(y_ui - y_uj))) \n",
    "#         # bpr_loss = -log_prob        \n",
    "#         # if self.reg > 0.:\n",
    "#         #     l2norm = (torch.sum(u_emb**2)/2. + torch.sum(p_emb**2)/2. + torch.sum(n_emb**2)/2.) / u_emb.shape[0]\n",
    "#         #     l2reg = self.reg * l2norm\n",
    "#         #     bpr_loss += l2reg\n",
    "\n",
    "#         # return bpr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, make_graph_data_set, optimizer, n_batch, device):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "    for _ in tqdm(range(n_batch), desc=\"Training...\"):\n",
    "        user, pos, neg = make_graph_data_set.sampling()\n",
    "        user = torch.LongTensor(user).to(device)\n",
    "        pos = torch.LongTensor(pos).to(device)\n",
    "        neg = torch.LongTensor(neg).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(user, pos, neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_val += loss.item()\n",
    "    return loss_val / n_batch\n",
    "\n",
    "def split_matrix(X, n_splits=10):\n",
    "    splits = []\n",
    "    chunk_size = X.shape[0] // n_splits\n",
    "    for i in range(n_splits):\n",
    "        start = i * chunk_size\n",
    "        end = X.shape[0] if i == n_splits - 1 else (i + 1) * chunk_size\n",
    "        splits.append(X[start:end])\n",
    "    return splits\n",
    "\n",
    "# def compute_ndcg_k(pred_items, test_items, test_indices, k):\n",
    "\n",
    "#     r = (test_items * pred_items).gather(1, test_indices)\n",
    "#     f = torch.from_numpy(np.log2(np.arange(2, k+2))).float().to(device)\n",
    "\n",
    "#     dcg = (r[:, :k]/f).sum(1)                                               \n",
    "#     dcg_max = (torch.sort(r, dim=1, descending=True)[0][:, :k]/f).sum(1)   \n",
    "#     ndcg = dcg/dcg_max                                                     \n",
    "\n",
    "#     ndcg[torch.isnan(ndcg)] = 0\n",
    "#     return ndcg\n",
    "\n",
    "def compute_ndcg_k(pred_items, test_items, k):\n",
    "    # DCG 계산\n",
    "    # print(f\"test_items : {test_items.shape}\")\n",
    "    topk_preds = pred_items[:, :k]\n",
    "    # print(f\"topk_preds shape : {topk_preds.shape}\")\n",
    "    tp = (test_items * topk_preds).sum(dim=1)\n",
    "    log_pos = torch.log2(torch.arange(2, k + 2, device=pred_items.device).float())\n",
    "    dcg = (tp / log_pos).sum(dim=1)\n",
    "    # IDCG 계산\n",
    "    ideal_tp = torch.sort(test_items, dim=1, descending=True)[0][:, :k]\n",
    "    idcg = (ideal_tp / log_pos).sum(dim=1)\n",
    "    idcg[idcg == 0] = 1  # 0으로 나누는 것을 방지\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg.mean().item()\n",
    "\n",
    "# def calculate_metrics(test_items, pred_items,test_indices, k, num_items):\n",
    "\n",
    "#     # ground_truth = torch.gather(test_items, 1, test_indices)\n",
    "#     ground_truth = torch.zeros(test_items.shape[0], num_items).to(test_items.device)\n",
    "#     ground_truth.scatter_(1, test_indices, 1)\n",
    "#     print(pred_items.shape)\n",
    "#     print(ground_truth.shape)\n",
    "#     tp = (ground_truth * pred_items).sum(dim=1)\n",
    "#     precision = tp / k\n",
    "#     recall = tp / test_items.sum(dim=1)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "#     accuracy = tp / (pred_items.sum(dim=1) + 1e-8)\n",
    "\n",
    "#     return recall.mean().item(), precision.mean().item(), f1.mean().item(), accuracy.mean().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_metrics(test_items, topk_preds):\n",
    "#     # True Positives\n",
    "#     TP = (test_items * topk_preds).sum(dim=1)\n",
    "#     # Recall@k: TP / (TP + FN)\n",
    "#     recall = TP / test_items.sum(dim=1)\n",
    "#     # Precision@k: TP / (TP + FP)\n",
    "#     precision = TP / topk_preds.sum(dim=1)\n",
    "#     # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "#     f1[torch.isnan(f1)] = 0.0  # handle NaN\n",
    "#     # Accuracy: TP / Total number of items\n",
    "#     accuracy = TP / test_items.shape[0]\n",
    "    \n",
    "#     return recall.mean().item(), precision.mean().item(), f1.mean().item(), accuracy.mean().item()\n",
    "\n",
    "\n",
    "# def evaluate(model, u_emb, i_emb, Rtr, Rte, k=10, device=None):\n",
    "    \n",
    "#     u_embeddings = all_embeddings[:model.n_users]\n",
    "#     i_embeddings = all_embeddings[model.n_users:]\n",
    "\n",
    "#     # split matrices\n",
    "#     ue_splits = split_matrix(u_emb)\n",
    "#     tr_splits = split_matrix(Rtr)\n",
    "#     te_splits = split_matrix(Rte)\n",
    "\n",
    "#     recall_k, ndcg_k, precision_list, f1_list, accuracy_list = [], [], [], [], []\n",
    "#     # compute results for split matrices\n",
    "#     for ue_f, tr_f, te_f in zip(ue_splits, tr_splits, te_splits):\n",
    "#         scores = torch.mm(ue_f.to(device), i_emb.to(device).t())\n",
    "\n",
    "#         test_items = torch.from_numpy(te_f.todense()).float().to(device)\n",
    "#         non_train_items = torch.from_numpy(1-(tr_f.todense())).float().to(device)\n",
    "#         scores = scores * non_train_items\n",
    "\n",
    "#         _, test_indices = torch.topk(scores, dim=1, k=k)\n",
    "        \n",
    "#         pred_items = torch.zeros_like(scores).float().to(device)\n",
    "#         pred_items.scatter_(dim=1, index=test_indices, src=torch.ones_like(test_indices).float().to(device))\n",
    "        \n",
    "#         topk_preds = torch.zeros_like(scores).float().to(device)\n",
    "#         topk_preds.scatter_(dim=1, index=test_indices[:, :k], value=1)\n",
    "\n",
    "#         recall, precision, f1, accuracy = calculate_metrics(test_items, topk_preds)\n",
    "#         recall_k.append(recall)\n",
    "#         precision_list.append(precision)\n",
    "#         f1_list.append(f1)\n",
    "#         accuracy_list.append(accuracy)\n",
    "\n",
    "#         ndcg_score = compute_ndcg_k(pred_items, test_items, test_indices, k)\n",
    "#         ndcg_k.append(ndcg_score.mean().item())\n",
    "\n",
    "#     # 리스트의 평균을 계산\n",
    "#     mean_recall = np.mean(recall_k)\n",
    "#     mean_precision = np.mean(precision_list)\n",
    "#     mean_f1 = np.mean(f1_list)\n",
    "#     mean_accuracy = np.mean(accuracy_list)\n",
    "#     mean_ndcg = np.mean(ndcg_k)\n",
    "\n",
    "#     return mean_ndcg, mean_recall, mean_precision, mean_f1, mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred_items, test_items, k):\n",
    "    \"\"\"\n",
    "    예측된 아이템 점수와 실제 테스트 아이템 간의 Recall, Precision, F1 점수를 계산합니다.\n",
    "\n",
    "    :param pred_items: 예측된 아이템 점수 (사용자 수 x 아이템 수)\n",
    "    :param test_items: 실제 테스트 아이템 (사용자 수 x 아이템 수), 1과 0으로 이루어진 행렬\n",
    "    :param k: 상위 k 개의 아이템을 고려\n",
    "    :return: recall@k, precision@k, F1@k\n",
    "    \"\"\"\n",
    "    _, topk_indices = torch.topk(pred_items, k=k, dim=1)\n",
    "    topk_preds = torch.zeros_like(pred_items).float()\n",
    "    topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "    # Recall@k: (TP) / (TP + FN)\n",
    "    tp = (test_items * topk_preds).sum(1)\n",
    "    recall = (tp / test_items.sum(1)).mean()\n",
    "\n",
    "    # Precision@k: (TP) / (TP + FP)\n",
    "    precision = (tp / k).mean()\n",
    "\n",
    "    # F1 Score: 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)  # NaN 값 처리\n",
    "\n",
    "    return recall.item(), precision.item(), f1.mean().item()\n",
    "def evaluate(model, Rtr, Rte, k, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = model.compute_embeddings()\n",
    "        u_embeddings = all_embeddings[:model.n_users]\n",
    "        i_embeddings = all_embeddings[model.n_users:]\n",
    "\n",
    "        scores = torch.matmul(u_embeddings, i_embeddings.T)\n",
    "\n",
    "        # 실제 테스트 데이터와 비교할 수 있도록 변환\n",
    "        test_items = torch.FloatTensor(Rte.toarray()).to(device)\n",
    "        \n",
    "        recall, precision, f1 = compute_metrics(scores, test_items, k)\n",
    "\n",
    "    return recall, precision, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, Rtr, Rte, k, device):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         all_embeddings = model.compute_embeddings()\n",
    "#         u_embeddings = all_embeddings[:model.n_users].to(device)\n",
    "#         i_embeddings = all_embeddings[model.n_users:].to(device)\n",
    "\n",
    "#         scores = torch.matmul(u_embeddings, i_embeddings.T)\n",
    "\n",
    "#         test_items = torch.FloatTensor(Rte.toarray()).to(device)\n",
    "#         non_train_items = torch.FloatTensor((~Rtr.toarray().astype(bool)).astype(int)).to(device)\n",
    "#         scores = scores * non_train_items  # Train에 포함되지 않은 아이템에 대해서만 점수를 계산\n",
    "\n",
    "#         _, topk_indices = torch.topk(scores, k=k, dim=1)\n",
    "#         topk_preds = torch.zeros(scores.shape).to(device)\n",
    "#         topk_preds.scatter_(1, topk_indices, 1)\n",
    "\n",
    "#         # Recall@10 계산\n",
    "#         hit = (test_items * topk_preds).sum(dim=1)\n",
    "#         recall_at_k = (hit / test_items.sum(dim=1)).mean()\n",
    "\n",
    "#         # Precision@10 계산\n",
    "#         precision_at_k = (hit / k).mean()\n",
    "\n",
    "#         # F1-Score 계산\n",
    "#         f1_score = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k + 1e-10)\n",
    "\n",
    "#         # Accuracy 계산\n",
    "#         accuracy = hit.sum() / (k * test_items.shape[0])\n",
    "\n",
    "#     return recall_at_k.item(), precision_at_k.item(), f1_score.item(), accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, Rtr, Rte, k=10, device=None):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         all_embeddings = model.compute_embeddings()\n",
    "#         u_embeddings = all_embeddings[:model.n_users].to(device)\n",
    "#         i_embeddings = all_embeddings[model.n_users:].to(device)\n",
    "\n",
    "#         # 테스트 데이터에 대한 행렬을 미리 계산\n",
    "#         test_items_matrix = torch.from_numpy(Rte.toarray()).float().to(device)\n",
    "#         non_train_items_matrix = torch.from_numpy((~Rtr.toarray().astype(bool)).astype(int)).float().to(device)\n",
    "\n",
    "#         scores = torch.matmul(u_embeddings, i_embeddings.T)\n",
    "#         scores = scores * non_train_items_matrix  # Train에 포함되지 않은 아이템에 대해서만 점수를 계산\n",
    "\n",
    "#         _, test_indices = torch.topk(scores, k=k, dim=1)\n",
    "#         pred_items = torch.zeros_like(scores).float()\n",
    "#         pred_items.scatter_(1, test_indices, 1)\n",
    "\n",
    "#         recall, precision, f1, accuracy = calculate_metrics(test_items_matrix, pred_items)\n",
    "#         ndcg_score = compute_ndcg_k(pred_items, test_items_matrix, test_indices, k)\n",
    "\n",
    "#     mean_recall = recall\n",
    "#     mean_precision = precision\n",
    "#     mean_f1 = f1\n",
    "#     mean_accuracy = accuracy\n",
    "#     mean_ndcg = ndcg_score.mean().item()\n",
    "\n",
    "#     return mean_ndcg, mean_recall, mean_precision, mean_f1, mean_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"emb_dim\": 64,\n",
    "    \"n_layers\": 3,\n",
    "    \"reg\": 0.00001,\n",
    "    \"node_dropout\": 0.1,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 50,\n",
    "    \"n_batch\": 256,  \n",
    "    \"model_path\": \"./models\",\n",
    "    \"model_name\": \"lightgcn_model.pt\",\n",
    "    'device' : 'device',\n",
    "    'weight_decay' : 0.0001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "data_path = '/home/siyun/ephemeral/lightgcn/LightGCN-PyTorch/data/amazon/amazon.csv'  \n",
    "preprocess = Preprocess(data_path=data_path, config=config)\n",
    "\n",
    "# 인접 행렬 및 사용자, 아이템 수 등 필요한 정보 가져오기\n",
    "adjacency_matrix = preprocess.adjacency_matrix\n",
    "num_users = preprocess.num_users\n",
    "num_items = preprocess.num_items\n",
    "\n",
    "model = LightGCN(\n",
    "    n_users=num_users,\n",
    "    n_items=num_items,\n",
    "    emb_dim=config['emb_dim'],  # 임베딩 차원\n",
    "    n_layers=config['n_layers'],  # GCN 레이어\n",
    "    reg=config['reg'],  # 정규화 \n",
    "    # node_dropout=0.1,  # 드롭아웃 \n",
    "    adj_mtx=adjacency_matrix,  # 인접 행렬\n",
    "    device = device\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 평가\n",
    "best_f1 = 0\n",
    "for epoch in range(1, config[\"num_epochs\"] + 1):\n",
    "    train_loss = train(\n",
    "        model=model,\n",
    "        make_graph_data_set=preprocess,\n",
    "        optimizer=optimizer,\n",
    "        n_batch=config[\"n_batch\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     mean_ndcg, mean_recall, mean_precision, mean_f1, mean_accuracy = evaluate(\n",
    "    #     # u_emb=model.u_final_embeddings.detach(),\n",
    "    #     # i_emb=model.i_final_embeddings.detach(),\n",
    "    #     Rtr=preprocess.user_item_matrix,\n",
    "    #     Rte=preprocess.user_item_matrix,\n",
    "    #     k=10,\n",
    "    #     device=device\n",
    "    # )\n",
    "    recall, precision, f1 = evaluate(model, \n",
    "                                       preprocess.user_item_matrix, \n",
    "                                       preprocess.user_item_matrix, \n",
    "                                       k=10, \n",
    "                                       device=device)\n",
    "\n",
    "    if best_f1 < f1:\n",
    "        best_f1 = f1\n",
    "        model_save_path = config[\"model_path\"]\n",
    "        if not os.path.exists(model_save_path):\n",
    "            os.mkdir(model_save_path)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_path, config[\"model_name\"]))\n",
    "        print(f\"Epoch {epoch}: New best model saved with F1: {best_f1:.4f}\")\n",
    "\n",
    "    print(f\"Recall@10: {recall}, Precision@10: {precision}, f1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tm1897/mlg_cs224w_project/tree/main\n",
    "\n",
    "def load_model(model_path, model, device):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def encode_session_items(preprocess, session_items):\n",
    "    # 새로운 사용자 세션의 아이템을 인코딩\n",
    "    encoded_items = [preprocess.item_encoder[item] for item in session_items if item in preprocess.item_encoder]\n",
    "    return encoded_items\n",
    "\n",
    "def infer_embeddings(model, encoded_session_items, num_users, num_items, device):\n",
    "    # 모든 사용자와 아이템의 임베딩을 계산\n",
    "    with torch.no_grad():\n",
    "        all_embeddings = model.compute_embeddings()\n",
    "        user_embeddings = all_embeddings[:num_users]\n",
    "        item_embeddings = all_embeddings[num_users:]\n",
    "        \n",
    "        # 새로운 사용자 세션의 아이템 임베딩을 평균내어 사용자 임베딩을 대체\n",
    "        if encoded_session_items:\n",
    "            print(f\"if encoded_session_items : 1\")\n",
    "            session_item_embeddings = item_embeddings[encoded_session_items].mean(dim=0).unsqueeze(0)\n",
    "        else:\n",
    "            # 세션에 아이템이 없는 경우 무작위 사용자 임베딩 사용\n",
    "            print(f\"if not encoded_session_items : 2\")\n",
    "            session_item_embeddings = user_embeddings[torch.randint(0, num_users, (1,))]\n",
    "    return session_item_embeddings, item_embeddings\n",
    "\n",
    "def recommend_items(session_user_embedding, item_embeddings, top_k):\n",
    "    # 사용자 임베딩과 모든 아이템 임베딩 간의 유사도를 계산\n",
    "    scores = torch.matmul(session_user_embedding, item_embeddings.T)\n",
    "    top_scores, top_indices = torch.topk(scores, k=top_k, dim=1)\n",
    "    return top_indices.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/siyun/ephemeral/lightgcn/LightGCN-PyTorch/data/amazon/'\n",
    "\n",
    "data = pd.read_csv(data_path + 'amazon.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B01GQE9CU2',\n",
       " 'B018V7WYZM',\n",
       " 'B01A96Y9RY',\n",
       " 'B00FXKK44E',\n",
       " 'B01D3GZUVQ',\n",
       " 'B012P0TZC6',\n",
       " 'B018FLQS24',\n",
       " 'B016QMOA38',\n",
       " 'B014JPKXW6',\n",
       " 'B015JBOMYE',\n",
       " 'B016LPMOW4']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['user_id'] == 'AZZXCFBNEWIBQ'].item_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 많은 item_id를 구매한 user_id: A3G5KDMFNRUXHB\n"
     ]
    }
   ],
   "source": [
    "user_item_counts = data.groupby('user_id')['item_id'].count()\n",
    "\n",
    "# item_id 개수가 가장 많은 user_id 찾기\n",
    "most_frequent_user_id = user_item_counts.idxmax()\n",
    "\n",
    "print(\"가장 많은 item_id를 구매한 user_id:\", most_frequent_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data[data['user_id'] == 'A3G5KDMFNRUXHB'].item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 데이터 로드\n",
    "model_path = config[\"model_path\"] + '/' + config[\"model_name\"]\n",
    "model = LightGCN(num_users, num_items, config['emb_dim'], config['n_layers'], config['reg'], adjacency_matrix, device)\n",
    "model = load_model(model_path, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if encoded_session_items : 1\n",
      "추천 아이템 ID: ['B0014F8TIU', 'B000YFSR5G', 'B0017LD0BM', 'B0017LGD34', 'B000YFSR4W', 'B00I0VHS10', 'B00ZOXFI1E', 'B0017U1KBK', 'B00201ER88', 'B000P0X15G']\n"
     ]
    }
   ],
   "source": [
    "# 새로운 유저 입력\n",
    "session_items = ['B01GQE9CU2',\n",
    " 'B018V7WYZM',\n",
    " 'B01A96Y9RY',\n",
    " 'B00FXKK44E',\n",
    " 'B01D3GZUVQ',\n",
    " 'B012P0TZC6',\n",
    " 'B018FLQS24',\n",
    " 'B016QMOA38',\n",
    " 'B014JPKXW6',\n",
    " 'B015JBOMYE',\n",
    " 'B016LPMOW4']  \n",
    "encoded_session_items = encode_session_items(preprocess, session_items)\n",
    "\n",
    "# 사용자와 아이템의 임베딩 계산\n",
    "session_user_embedding, item_embeddings = infer_embeddings(model, encoded_session_items, num_users, num_items, device)\n",
    "\n",
    "# 상위 N개의 추천 아이템 생성\n",
    "top_k = 10  # 추천하고 싶은 아이템의 수\n",
    "recommended_item_indices = recommend_items(session_user_embedding, item_embeddings, top_k)\n",
    "\n",
    "# 인코딩된 아이템 인덱스를 실제 아이템 ID로 디코딩\n",
    "recommended_item_ids = [preprocess.item_decoder[idx] for idx in recommended_item_indices if idx in preprocess.item_decoder]\n",
    "print(\"추천 아이템 ID:\", recommended_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24128    B01GQE9CU2\n",
       "24129    B018V7WYZM\n",
       "24130    B01A96Y9RY\n",
       "24131    B00FXKK44E\n",
       "24132    B01D3GZUVQ\n",
       "24133    B012P0TZC6\n",
       "24134    B018FLQS24\n",
       "24135    B016QMOA38\n",
       "24136    B014JPKXW6\n",
       "24137    B015JBOMYE\n",
       "24138    B016LPMOW4\n",
       "Name: item_id, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_data = data[data['user_id'] == 'AZZXCFBNEWIBQ']['item_id']\n",
    "user_id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천된 아이템 목록에 있는 아이템의 수: 0\n"
     ]
    }
   ],
   "source": [
    "# 추천된 아이템 목록에 있는 아이템의 등장 횟수 확인\n",
    "\n",
    "user_id_data = data[data['user_id'] == 'AZZXCFBNEWIBQ']\n",
    "\n",
    "count_recommended_items = user_id_data[user_id_data['item_id'].isin(recommended_item_ids)].shape[0]\n",
    "\n",
    "print(\"추천된 아이템 목록에 있는 아이템의 수:\", count_recommended_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
