{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ug-br-pPu9vZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ansck\\AppData\\Local\\Temp\\ipykernel_32464\\3398555383.py:4: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRKDSg4u9vc"
      },
      "source": [
        "# 1. 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "MEhK_fLIu9vd"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'data_path' : \"C:/Users/ansck/python/추천시스템/\" , # 데이터 경로\n",
        "    'valid_samples' : 1, # 검증에 사용할 sample 수\n",
        "    'seed' : 22,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjDxy0fJu9vf"
      },
      "source": [
        "# 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "W64BYWl0u9vg"
      },
      "outputs": [],
      "source": [
        "class MakeMatrixDataSet():\n",
        "    \"\"\"\n",
        "    MatrixDataSet 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.column_names = ['productId','userId','rating','timestamp']\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'AMAZON_FASHION.csv'), names=self.column_names)\n",
        "        \n",
        "        self.df = self.preprocess_data(min_len = 5)\n",
        "        \n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('productId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['productId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "        \n",
        "    def preprocess_data(self, min_len = 5):\n",
        "        \"\"\"\n",
        "        min_len 이하의 유저 sequence는 삭제\n",
        "        \"\"\"\n",
        "        userId_counts = self.df['userId'].value_counts()\n",
        "        valid_users = userId_counts[userId_counts >= min_len].index\n",
        "        df_validusers = self.df[self.df['userId'].isin(valid_users)]\n",
        "        \n",
        "        return df_validusers\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Returns:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "    \n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        sequence_data 생성\n",
        "\n",
        "        Returns:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['timestamp']):\n",
        "            users[user].append(item)\n",
        "        \n",
        "        for user in users:\n",
        "            np.random.seed(self.config.seed)\n",
        "\n",
        "            user_total = users[user]\n",
        "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
        "            train = list(set(user_total) - set(valid))\n",
        "\n",
        "            user_train[user] = train\n",
        "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
        "\n",
        "        return user_train, user_valid\n",
        "    \n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid\n",
        "\n",
        "    def make_matrix(self, user_list, train = True):\n",
        "        \"\"\"\n",
        "        user_item_dict를 바탕으로 행렬 생성\n",
        "        \"\"\"\n",
        "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
        "        for idx, user in enumerate(user_list):\n",
        "            if train:\n",
        "                mat[idx, self.user_train[user.item()]] = 1\n",
        "            else:\n",
        "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
        "        return mat\n",
        "\n",
        "    def make_sparse_matrix(self):\n",
        "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
        "        for user in self.user_train.keys():\n",
        "            item_list = self.user_train[user]\n",
        "            X[user, item_list] = 1.0\n",
        "        \n",
        "        self.X = X.tocsr()        \n",
        "        return X.tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "IldCGmY8u9vh"
      },
      "outputs": [],
      "source": [
        "class AEDataSet(Dataset):\n",
        "    def __init__(self, num_user):\n",
        "        self.num_user = num_user\n",
        "        self.users = [i for i in range(num_user)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_user\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        user = self.users[idx]\n",
        "        return torch.LongTensor([user])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysia457Su9vi"
      },
      "source": [
        "# 3. 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "TVXWUTLpSh8_"
      },
      "outputs": [],
      "source": [
        "class EASE():\n",
        "    def __init__(self, X, reg):\n",
        "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
        "        self.reg = reg\n",
        "    \n",
        "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
        "        \"\"\"\n",
        "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
        "\n",
        "        Arguments:\n",
        "        ----------\n",
        "        X = Adjacency matrix, scipy sparse matrix\n",
        "        \"\"\"\n",
        "        coo = X.tocoo().astype(np.float32)\n",
        "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
        "        v = torch.FloatTensor(coo.data)\n",
        "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
        "        return res\n",
        "    \n",
        "    def fit(self):\n",
        "        '''\n",
        "\n",
        "        진짜 정말 간단한 식으로 모델을 만듬\n",
        "        '''\n",
        "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
        "        diagIndices = torch.eye(G.shape[0]) == 1\n",
        "        G[diagIndices] += self.reg\n",
        "\n",
        "        P = G.inverse()\n",
        "        B = P / (-1 * P.diag())\n",
        "        B[diagIndices] = 0\n",
        "        \n",
        "        self.B = B\n",
        "\n",
        "        self.pred = self.X.to_dense() @ B\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwSexh43u9vk"
      },
      "source": [
        "# 4. 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "nws4JO2_rgQP"
      },
      "outputs": [],
      "source": [
        "def get_ndcg(pred_list, true_list):\n",
        "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
        "    dcg = 0\n",
        "    for rank, pred in enumerate(pred_list):\n",
        "        if pred in true_list:\n",
        "            dcg += 1 / np.log2(rank + 2)\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg\n",
        "\n",
        "# hit == recall == precision\n",
        "def get_hit(pred_list, true_list):\n",
        "    hit_list = set(true_list) & set(pred_list)\n",
        "    hit = len(hit_list) / len(true_list)\n",
        "    return hit\n",
        "\n",
        "def evaluate(model, X, user_train, user_valid):\n",
        "\n",
        "    mat = torch.from_numpy(X)\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    recon_mat1 = model.pred.cpu()\n",
        "    print(recon_mat1)\n",
        "    recon_mat1[mat == 1] = -np.inf\n",
        "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
        "    print(rec_list1.shape)\n",
        "\n",
        "    for user, rec1 in tqdm(enumerate(rec_list1)):\n",
        "        uv = user_valid[user]\n",
        "\n",
        "        # ranking\n",
        "        up = rec1[-10:].cpu().numpy().tolist()[::-1]\n",
        "        print(user,up)\n",
        "\n",
        "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
        "        HIT += get_hit(pred_list = up, true_list = uv)\n",
        "\n",
        "    NDCG /= len(user_train)\n",
        "    HIT /= len(user_train)\n",
        "    \n",
        "    return NDCG, HIT\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 추천 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_for_new_user(item_list, ease_model, make_matrix_data_set, num_recommendations=10):\n",
        "    \"\"\"\n",
        "    새로운 사용자에 대한 항목 추천을 생성합니다.\n",
        "\n",
        "    :param item_list: 새 사용자가 상호 작용한 항목 목록입니다.\n",
        "    :param ease_model: 훈련된 EASE 모델입니다.\n",
        "    :param make_matrix_data_set: 데이터 처리 클래스의 인스턴스입니다.\n",
        "    :param num_recommendations: 반환할 추천 항목의 수입니다.\n",
        "    :return: 추천된 항목 ID 목록입니다.\n",
        "    \"\"\"\n",
        "    # 새 사용자 항목 인덱스 생성\n",
        "    user_item_indices = [make_matrix_data_set.item_encoder[item] for item in item_list if item in make_matrix_data_set.item_encoder]\n",
        "\n",
        "    # 새 사용자 벡터 초기화\n",
        "    new_user_vector = torch.zeros((1, make_matrix_data_set.num_item))\n",
        "\n",
        "    # 사용자 벡터에 항목 인덱스 적용\n",
        "    new_user_vector[0, user_item_indices] = 1\n",
        "\n",
        "    # EASE 모델을 사용한 추천 생성\n",
        "    new_user_vector = new_user_vector.to(device)\n",
        "    user_pred = new_user_vector @ ease_model.B\n",
        "\n",
        "    # 이미 상호 작용한 항목은 제외\n",
        "    user_pred[0, user_item_indices] = -np.inf\n",
        "\n",
        "    # 상위 N개 추천\n",
        "    recommended_indices = torch.topk(user_pred, k=num_recommendations, dim=1).indices.cpu().numpy().flatten()\n",
        "    recommended_items = [make_matrix_data_set.item_decoder[idx] for idx in recommended_indices]\n",
        "\n",
        "    return recommended_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_top_n_recommendations_for_user_id(user_id, ease_model, make_matrix_data_set, n=10):\n",
        "    \"\"\"\n",
        "    주어진 사용자 ID에 대해 상위 N개의 추천 항목을 반환합니다.\n",
        "\n",
        "    :param user_id: 추천을 생성할 사용자의 ID\n",
        "    :param ease_model: 학습된 EASE 모델\n",
        "    :param make_matrix_data_set: MakeMatrixDataSet 인스턴스\n",
        "    :param n: 반환할 추천 항목의 수\n",
        "    :return: 상위 N개의 추천 항목 리스트\n",
        "    \"\"\"\n",
        "    # 사용자 ID를 사용자 인덱스로 변환\n",
        "    if user_id in make_matrix_data_set.user_encoder:\n",
        "        user_index = make_matrix_data_set.user_encoder[user_id]\n",
        "    else:\n",
        "        print(\"User ID not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    # 사용자 인덱스에 해당하는 행을 추출\n",
        "    user_vector = make_matrix_data_set.X[user_index, :].toarray()\n",
        "    user_vector = torch.from_numpy(user_vector).float().to(device)\n",
        "\n",
        "    # 모델을 사용해 예측 점수를 계산\n",
        "    user_pred_scores = user_vector @ ease_model.B\n",
        "\n",
        "    # 이미 상호작용한 항목은 추천에서 제외\n",
        "    user_pred_scores[0, user_vector.nonzero()] = -np.inf\n",
        "\n",
        "    # 상위 N개의 추천 항목 인덱스를 반환\n",
        "    top_n_indices = torch.topk(user_pred_scores, k=n, dim=1).indices.cpu().numpy().flatten()\n",
        "\n",
        "    # 인덱스를 항목 ID로 변환\n",
        "    top_n_items = [make_matrix_data_set.item_decoder[idx] for idx in top_n_indices]\n",
        "\n",
        "    return top_n_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gupkaJHMslCi"
      },
      "source": [
        "# 5. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "HFOr6Wmbq9pW"
      },
      "outputs": [],
      "source": [
        "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
        "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
        "X = make_matrix_data_set.make_sparse_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = EASE(X = X, reg = 1000)\n",
        "model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['B00008JOQI', 'B00IQZZ9JI', 'B00KA3UV0Q', 'B00KW4L9XQ', 'B00RBJZ7EC']"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('AMAZON_FASHION.csv', names= ['productId','userId','rating','timestamp'])\n",
        "userId_counts = data['userId'].value_counts()\n",
        "valid_users = userId_counts[userId_counts >= 5].index\n",
        "data = data[data['userId'].isin(valid_users)]\n",
        "data[data['userId']=='AAQO19HKS86MQ']['productId'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "#new_user=['B0007MV6PO', 'B0008F6WMM', 'B0009A1EA6', 'B01HJ0SIF2', 'B01HJG5NLI']\n",
        "\n",
        "#'AAQO19HKS86MQ' 유저의 ITEM\n",
        "new_user=['B00008JOQI', 'B00IQZZ9JI', 'B00KA3UV0Q', 'B00KW4L9XQ', 'B00RBJZ7EC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "추천된 항목: ['B00MIMOVB2', 'B00PJIPZGW', 'B00LMUA6C4', 'B00LMU9NE6', 'B00KA3VEG6', 'B00FG35RU4', 'B00MXG42US', 'B00KA3V9JS', 'B00KW4LCCE', 'B00LMU7GHM']\n"
          ]
        }
      ],
      "source": [
        "recommendations = recommend_for_new_user(new_user, model, make_matrix_data_set)\n",
        "print(\"추천된 항목:\", recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 recommendations for user AAQO19HKS86MQ: ['B00MIMOVB2', 'B00PJIPZGW', 'B00LMUA6C4', 'B00LMU9NE6', 'B00KA3VEG6', 'B00FG35RU4', 'B00MXG42US', 'B00KA3V9JS', 'B00KW4LCCE', 'B00LMU7GHM']\n"
          ]
        }
      ],
      "source": [
        "user_id = 'AAQO19HKS86MQ'\n",
        "top_n_recommendations = get_top_n_recommendations_for_user_id(user_id, model, make_matrix_data_set, n=10)\n",
        "print(f\"Top {len(top_n_recommendations)} recommendations for user {user_id}: {top_n_recommendations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzhvIGPhrYov",
        "outputId": "8678797c-2c8c-4d80-856f-e1dbd9296391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 18405.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 1000| NDCG@10: 0.04791| HIT@10: 0.19096\n",
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 23019.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 100| NDCG@10: 0.04772| HIT@10: 0.19016\n",
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 25819.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 10| NDCG@10: 0.04528| HIT@10: 0.18209"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 16598.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 1| NDCG@10: 0.04185| HIT@10: 0.16918\n",
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 9750.19it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 0.1| NDCG@10: 0.03655| HIT@10: 0.14900\n",
            "torch.Size([3718, 13197])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3718it [00:00, 15427.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reg: 0.01| NDCG@10: 0.03796| HIT@10: 0.16756\n"
          ]
        }
      ],
      "source": [
        "for reg in [1000, 100, 10, 1, 0.1, 0.01]:\n",
        "    model = EASE(X = X, reg = reg)\n",
        "    model.fit()\n",
        "    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n",
        "    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMoF11Uk2GPLa5U/j8sZ0UD",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO",
      "name": "EASE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
